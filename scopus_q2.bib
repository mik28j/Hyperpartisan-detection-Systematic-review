Scopus
EXPORT DATE: 27 October 2023

@CONFERENCE{Tran20204359,
	author = {Tran, Minh},
	title = {How biased are American media outlets? A framework for presentation bias regression},
	year = {2020},
	journal = {Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020},
	pages = {4359 – 4364},
	doi = {10.1109/BigData50022.2020.9377987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103814921&doi=10.1109%2fBigData50022.2020.9377987&partnerID=40&md5=e1fe4b87888e4ff379f1901fe3d514ec},
	abstract = {Media bias is a pressing issue in our society that can increase political polarization. To address the issue, previous studies mainly develop supervised learning models to identify bias at the article level, which not only requires expensive data collection but also careful features selection. An alternative approach to combat media bias focuses on the source level, which can help news aggregators promptly filter unreliable news based on their sources. Despite being a promising approach, the detection of biases at the source level remains largely unexplored. In this study, we propose a novel unsupervised framework to estimate presentation bias of news sources. The framework first uses a retrieval engine to form groups of related articles, then constructs pairwise biases between news sources using Aspect-based Sentiment Analysis (ABSA) and finally, assigns bias scores for each source with a graph-based algorithm. Using a dataset of approximately 83K articles from 14 news sources, we validate the results of our framework with 3 benchmarks and find that our approach can provide reliable bias ratings, with a Pearson correlation coefficient of up to 0.92. We further discuss the possibility of extending the framework to identify selection bias. © 2020 IEEE.},
	author_keywords = {media bias; politics; sentiment analysis},
	keywords = {Correlation methods; Graph algorithms; Graphic methods; Sentiment analysis; Data collection; Features selection; Graph-based algorithms; News aggregators; Pearson correlation coefficients; Presentation bias; Retrieval engines; Selection bias; Big data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Martín-Forero2022,
	author = {Martín-Forero, Álvaro García-Ochoa and López, Alejandro Massotti and Segura-Bedmar, Isabel},
	title = {UC3MDeep at PoliticEs 2022: Exploring Traditional Machine Learning Algorithms for Political Ideology Detection},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137331717&partnerID=40&md5=6937332cdd16c4bcb7876be47e24d2eb},
	abstract = {Social media has played an important role in shaping political discourse over the last decade. It is often perceived to have increased political polarization, thanks to the scale of discussions and their public nature. Automatic political ideology detection allows us to identify the bias of information sources as well as professionals such as journalists. It has also become a relevant area due to its successful application to user behaviour analysis and prediction of malicious user versus legitimate user. This paper describes our participation at PoliticEs@IberLEF2022 shared task, whose goal is classify the political ideology of a person as well as other related information such as profession or gender. We explore several machine learning models to address the task of political ideology detection. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {kNN; Logistic Regression; Political ideology detection; Random Forest; Text classification},
	keywords = {Behavioral research; Classification (of information); Machine learning; Random forests; Text processing; Information professionals; KNN; Logistics regressions; Machine learning algorithms; Political discourse; Political ideologies; Political ideology detection; Random forests; Social media; Text classification; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Paraschiv20201853,
	author = {Paraschiv, Andrei and Cercel, Dumitru-Clementin and Dascalu, Mihai},
	title = {UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific Trained BERT},
	year = {2020},
	journal = {14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings},
	pages = {1853 – 1857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106134200&partnerID=40&md5=34a05bbbba293c797cd48e4f9ea51963},
	abstract = {Manipulative and misleading news have become a commodity for some online news outlets and these news have gained a significant impact on the global mindset of people. Propaganda is a frequently employed manipulation method having as goal to influence readers by spreading ideas meant to distort or manipulate their opinions. This paper describes our participation in the SemEval-2020, Task 11: Detection of Propaganda Techniques in News Articles competition. Our approach considers specializing a pre-trained BERT model on propagandistic and hyperpartisan news articles, enabling it to create more adequate representations for the two subtasks, namely propaganda Span Identification (SI) and propaganda Technique Classification (TC). Our proposed system achieved a F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36 teams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th from 32 teams. © 2020 14th International Workshops on Semantic Evaluation, SemEval 2020 - co-located 28th International Conference on Computational Linguistics, COLING 2020, Proceedings. All rights reserved.},
	keywords = {Classification (of information); Computational linguistics; Domain specific; F1 scores; Manipulation methods; News articles; Online news; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Diehl2022,
	author = {Diehl, Trevor and Lee, Sangwon},
	title = {Testing the cognitive involvement hypothesis on social media: 'News finds me' perceptions, partisanship, and fake news credibility},
	year = {2022},
	journal = {Computers in Human Behavior},
	volume = {128},
	doi = {10.1016/j.chb.2021.107121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120646355&doi=10.1016%2fj.chb.2021.107121&partnerID=40&md5=4dde391133f65c750d6b9824f0c5cb60},
	abstract = {Social media has been implicated in the proliferation of fabricated news narratives posing as professional journalism. In response, scholars have prioritized the study of the antecedents and outcomes of citizen's ability to detect so-called ‘fake news’. Growing evidence supports the cognitive involvement hypothesis, which states that deeper reflection and elaboration on news content increases one's tendency to correctly identify fake news. This study adds to this literature by exploring connections between reliance on social media for news and emergent scholarship on the News Finds Me Perception (NFMP). We argue that the NFMP represents a low-effort cognitive style of attention to news and therefore, high NFMP respondents are more likely to evaluate fake news as credible. Furthermore, we examine whether this association holds despite partisan affiliation. Panel survey data from the United States provide robust evidence that the NFMP is associated with inaccurate assessments of both apolitical and pro-conservative fake news stories. Moderation analyses show that NFMP is a boundary condition for media effects; reliance on social media for news only leads to fake news acceptance when people hold the NFMP, and this effect exacerbates partisan motivated reasoning. Implications for theory building are discussed. © 2021 Elsevier Ltd},
	author_keywords = {Cognitive elaboration; Fake news; Heuristics; News credibility; News finds me perception; Partisan motivated reasoning; Social media},
	keywords = {Behavioral research; Fake detection; Cognitive elaboration; Cognitive styles; Fake news; Heuristic; News content; News credibility; News find me perception; Partisan motivated reasoning; Social media; Survey data; adult; article; attention; disinformation; female; heuristics; human; human experiment; male; perception; reasoning; social media; United States; Social networking (online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Alonso2021,
	author = {Alonso, Miguel A. and Vilares, David and Gómez-Rodríguez, Carlos and Vilares, Jesús},
	title = {Sentiment analysis for fake news detection},
	year = {2021},
	journal = {Electronics (Switzerland)},
	volume = {10},
	number = {11},
	doi = {10.3390/electronics10111348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107211423&doi=10.3390%2felectronics10111348&partnerID=40&md5=fa92c5b7d92b07debbd176638d45dfaf},
	abstract = {In recent years, we have witnessed a rise in fake news, i.e., provably false pieces of information created with the intention of deception. The dissemination of this type of news poses a serious threat to cohesion and social well-being, since it fosters political polarization and the distrust of people with respect to their leaders. The huge amount of news that is disseminated through social media makes manual verification unfeasible, which has promoted the design and implementation of automatic systems for fake news detection. The creators of fake news use various stylistic tricks to promote the success of their creations, with one of them being to excite the sentiments of the recipients. This has led to sentiment analysis, the part of text analytics in charge of determining the polarity and strength of sentiments expressed in a text, to be used in fake news detection approaches, either as a basis of the system or as a complementary element. In this article, we study the different uses of sentiment analysis in the detection of fake news, with a discussion of the most relevant elements and shortcomings, and the requirements that should be met in the near future, such as multilingualism, explainability, mitigation of biases, or treatment of multimedia elements. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Fake news; Opinion mining; Sentiment analysis; Social media},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhang20191072,
	author = {Zhang, Chiyu and Rajendran, Arun and Abdul-Mageed, Muhammad},
	title = {UBC-NLP at SemEval-2019 task 4: Hyperpartisan news detection with attention-based Bi-LSTMs},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1072 – 1077},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118595407&partnerID=40&md5=8389fc6fe1a41ad41279d7e33b7503a3},
	abstract = {We present our deep learning models submitted to the SemEval-2019 Task 4 competition focused at Hyperpartisan News Detection. We acquire best results with a Bi-LSTM network equipped with a self-attention mechanism. Among 33 participating teams, our submitted system ranks top 7 (65.3% accuracy) on the labels-by-publisher sub-task and top 24 out of 44 teams (68.3% accuracy) on the labels-by-article sub-task (65.3% accuracy). We also report a model that scores higher than the 8th ranking system (78.5% accuracy) on the labels-by-article sub-task. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Attention mechanisms; Learning models; Participating teams; Ranking system; Subtask; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bastos2021863,
	author = {Bastos, Marco and Walker, Shawn and Simeone, Michael},
	title = {The IMPED Model: Detecting Low-Quality Information in Social Media},
	year = {2021},
	journal = {American Behavioral Scientist},
	volume = {65},
	number = {6},
	pages = {863 – 883},
	doi = {10.1177/0002764221989776},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100483009&doi=10.1177%2f0002764221989776&partnerID=40&md5=c7c0622508af5f3e42ced6409e2119d3},
	abstract = {This article introduces a model for detecting low-quality information we refer to as the Index of Measured-diversity, Partisan-certainty, Ephemerality, and Domain (IMPED). The model purports that low-quality information is characterized by ephemerality, as opposed to quality content that is designed for permanence. The IMPED model leverages linguistic and temporal patterns in the content of social media messages and linked webpages to estimate a parametric survival model and the likelihood the content will be removed from the internet. We review the limitations of current approaches for the detection of problematic content, including misinformation and false news, which are largely based on fact checking and machine learning, and detail the requirements for a successful implementation of the IMPED model. The article concludes with a review of examples taken from the 2018 election cycle and the performance of the model in identifying low-quality information as a proxy for problematic content. © 2021 SAGE Publications.},
	author_keywords = {content moderation; diversity index; misinformation; partisanship; web archive},
	keywords = {article; election; human; information center; Internet; machine learning; misinformation; social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Potthast2018231,
	author = {Potthast, Martin and Kiesel, Johannes and Reinartz, Kevin and Bevendorff, Janek and Stein, Benno},
	title = {A stylometric inquiry into hyperpartisan and fake news},
	year = {2018},
	journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
	volume = {1},
	pages = {231 – 240},
	doi = {10.18653/v1/p18-1022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063109511&doi=10.18653%2fv1%2fp18-1022&partnerID=40&md5=6799a33d249157cc3a119ea9a609e9c3},
	abstract = {We report on a comparative style analysis of hyperpartisan (extremely one-sided) news and fake news. A corpus of 1,627 articles from 9 political publishers, three each from the mainstream, the hyperpartisan left, and the hyperpartisan right, have been fact-checked by professional journalists at BuzzFeed: 97% of the 299 fake news articles identified are also hyperpartisan. We show how a style analysis can distinguish hyperpartisan news from the mainstream (F1 = 0.78), and satire from both (F1 = 0.81). But stylometry is no silver bullet as style-based fake news detection does not work (F1 = 0.46). We further reveal that left-wing and right-wing news share significantly more stylistic similarities than either does with the mainstream. This result is robust: it has been confirmed by three different modeling approaches, one of which employs Unmasking in a novel way. Applications of our results include partisanship detection and pre-screening for semi-automatic fake news detection. © 2018 Association for Computational Linguistics},
	keywords = {Model approach; News articles; Semi-automatics; Stylistic similarity; Stylometry; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 219; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Graham2021127,
	author = {Graham, Timothy and Bruns, Axel and Angus, Daniel and Hurcombe, Edward and Hames, Sam},
	title = {#IStandWithDan versus #DictatorDan: the polarised dynamics of Twitter discussions about Victoria’s COVID-19 restrictions},
	year = {2021},
	journal = {Media International Australia},
	volume = {179},
	number = {1},
	pages = {127 – 148},
	doi = {10.1177/1329878X20981780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097950776&doi=10.1177%2f1329878X20981780&partnerID=40&md5=1c702fabc64333f95ad627f90e3eaa38},
	abstract = {In this article, we examine two interrelated hashtag campaigns that formed in response to the Victorian State Government’s handling of Australia’s most significant COVID-19 second wave of mid-to-late 2020. Through a mixed-methods approach that includes descriptive statistical analysis, qualitative content analysis, network analysis, computational sentiment analysis and social bot detection, we reveal how a small number of hyper-partisan pro- and anti-government campaigners were able to mobilise ad hoc communities on Twitter, and – in the case of the anti-government hashtag campaign – co-opt journalists and politicians through a multi-step flow process to amplify their message. Our comprehensive analysis of Twitter data from these campaigns offers insights into the evolution of political hashtag campaigns, how actors involved in these specific campaigns were able to exploit specific dynamics of Twitter and the broader media and political establishment to progress their hyper-partisan agendas, and the utility of mixed-method approaches in helping render the dynamics of such campaigns visible. © The Author(s) 2020.},
	author_keywords = {clicktivism; Coronavirus; COVID-19; disinformation; hashtag activism; misinformation; multi-step flow model; social media; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sánchez-Junquera20211244,
	author = {Sánchez-Junquera, Javier and Rosso, Paolo and Montes-Y-Gómez, Manuel and Ponzetto, Simone P.},
	title = {Masking and Transformer-based Models for Hyperpartisanship Detection in News},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1244 – 1251},
	doi = {10.26615/978-954-452-072-4_140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123606605&doi=10.26615%2f978-954-452-072-4_140&partnerID=40&md5=04404f1d0eb3e05f7c77dd6f7ca3e562},
	abstract = {Hyperpartisan news show an extreme manipulation of reality based on an underlying and extreme ideological orientation. Because of its harmful effects at reinforcing one's bias and the posterior behavior of people, hyperpartisan news detection has become an important task for computational linguists. In this paper, we evaluate two different approaches to detect hyperpartisan news. First, a text masking technique that allows us to compare style vs. topic-related features in a different perspective from previous work. Second, the transformer-based models BERT, XLM-RoBERTa, and M-BERT, known for their ability to capture semantic and syntactic patterns in the same representation. Our results corroborate previous research on this task in that topic-related features yield better results than style-based ones, although they also highlight the relevance of using higher-length n-grams. Furthermore, they show that transformer-based models are more effective than traditional methods, but this at the cost of greater computational complexity and lack of transparency. Based on our experiments, we conclude that the beginning of the news show relevant information for the transformers at distinguishing effectively between left-wing, mainstream, and right-wing orientations. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {Harmful effects; Masking technique; N-grams; Semantic pattern; Syntactic patterns; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@CONFERENCE{Szwoch202286,
	author = {Szwoch, Joanna and Staszkow, Mateusz and Rzepka, Rafal and Araki, Kenji},
	title = {Creation of Polish Online News Corpus for Political Polarization Studies},
	year = {2022},
	journal = {1st Workshop on Natural Language Processing for Political Sciences, PoliticalNLP 2022 - Proceedings, as part of the 13th Edition of the Language Resources and Evaluation Conference, LREC 2022},
	pages = {86 – 90},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145964536&partnerID=40&md5=e4f8bb02d0beedb8627f147acf8a9720},
	abstract = {In this paper we describe a Polish news corpus as an attempt to create a filtered, organized and representative set of texts coming from contemporary online press articles from two major Polish TV news providers: commercial TVN24 and state-owned TVP Info. The process consists of web scraping, data cleaning and formatting. A random sample was selected from prepared data to perform a classification task. The random forest achieved the best prediction results out of all considered models. We believe that this dataset is a valuable contribution to existing Polish language corpora as online news are considered to be formal and relatively mistake-free, therefore, a reliable source of correct written language, unlike other online platforms such as blogs or social media. Furthermore, to our knowledge, such corpus from this period of time has not been created before. In the future we would like to expand this dataset with articles coming from other online news providers, repeat the classification task on a bigger scale, utilizing other algorithms. Our data analysis outcomes might be a relevant basis to improve research on a political polarization and propaganda techniques in media. © 2022 European Language Resources Association (ELRA).},
	author_keywords = {classification; news corpus; NLP; Polish language; web scraping},
	keywords = {Polarization; Classification tasks; Data cleaning; Data formatting; News corpora; Online news; Polarization study; Polish language; Random sample; TV news; Web scrapings; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Alabdulkarim2019985,
	author = {Alabdulkarim, Amal and Alhindi, Tariq},
	title = {Spider-Jerusalem at SemEval-2019 task 4: Hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {985 – 989},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118544610&partnerID=40&md5=8c3cce1f0b3e6417819a2ab570794c18},
	abstract = {This paper describes our system for detecting hyperpartisan news articles, which was submitted for the shared task in SemEval 2019 on Hyperpartisan News Detection. We developed a Support Vector Machine (SVM) model that uses TF-IDF of tokens, Language Inquiry and Word Count (LIWC) features, and structural features such as number of paragraphs and hyperlink count in an article. The model was trained on 645 articles from two classes: mainstream and hyperpartisan. Our system was ranked seventeenth out of forty two participating teams in the binary classification task with an accuracy score of 0.742 on the blind test set (the accuracy of the top ranked system was 0.822). We provide a detailed description of our preprocessing steps, discussion of our experiments using different combinations of features, and analysis of our results and prediction errors. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Semantics; Support vector machines; As numbers; Binary classification; Blind test; Classification tasks; Hyperlinks; Jerusalem; News articles; Participating teams; Structural feature; Support vector machine models; Hypertext systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Rao2021,
	author = {Rao, Ashwin and Morstatter, Fred and Hu, Minda and Chen, Emily and Burghardt, Keith and Ferrara, Emilio and Lerman, Kristina},
	title = {Political partisanship and antiscience attitudes in online discussions about COVID-19: Twitter content analysis},
	year = {2021},
	journal = {Journal of Medical Internet Research},
	volume = {23},
	number = {6},
	doi = {10.2196/26692},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108303866&doi=10.2196%2f26692&partnerID=40&md5=cfb0cd561e7162e9842988ef02ff6d74},
	abstract = {Background: The novel coronavirus pandemic continues to ravage communities across the United States. Opinion surveys identified the importance of political ideology in shaping perceptions of the pandemic and compliance with preventive measures. Objective: The aim of this study was to measure political partisanship and antiscience attitudes in the discussions about the pandemic on social media, as well as their geographic and temporal distributions. Methods: We analyzed a large set of tweets from Twitter related to the pandemic, collected between January and May 2020, and developed methods to classify the ideological alignment of users along the moderacy (hardline vs moderate), political (liberal vs conservative), and science (antiscience vs proscience) dimensions. Results: We found a significant correlation in polarized views along the science and political dimensions. Moreover, politically moderate users were more aligned with proscience views, while hardline users were more aligned with antiscience views. Contrary to expectations, we did not find that polarization grew over time; instead, we saw increasing activity by moderate proscience users. We also show that antiscience conservatives in the United States tended to tweet from the southern and northwestern states, while antiscience moderates tended to tweet from the western states. The proportion of antiscience conservatives was found to correlate with COVID-19 cases. Conclusions: Our findings shed light on the multidimensional nature of polarization and the feasibility of tracking polarized opinions about the pandemic across time and space through social media data. ©Ashwin Rao, Fred Morstatter, Minda Hu, Emily Chen, Keith Burghardt, Emilio Ferrara, Kristina Lerman.},
	author_keywords = {COVID-19; Infodemic; Infodemiology; Infoveillance; Multidimensional polarization; Social media; Social network; Twitter},
	keywords = {COVID-19; Humans; Internet Use; Politics; SARS-CoV-2; Social Media; Telemedicine; algorithm; Article; classification; content analysis; coronavirus disease 2019; expectation; geographic distribution; human; ideology; medical information; pandemic; patient attitude; politics; public health; public opinion; science; search engine; social media; social network; text messaging; United States; social media; telemedicine; therapy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Hosseinia2021547,
	author = {Hosseinia, Marjan and Dragut, Eduard and Boumber, Dainis and Mukherjee, Arjun},
	title = {On the Usefulness of Personality Traits in Opinion-oriented Tasks},
	year = {2021},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {547 – 556},
	doi = {10.26615/978-954-452-072-4_062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123622306&doi=10.26615%2f978-954-452-072-4_062&partnerID=40&md5=aafa3afbcb4d2df31601f33a0c0a93df},
	abstract = {We use a deep bidirectional transformer to extract the Myers-Briggs personality type from user-generated data in a multi-label and multi-class classification setting. Our dataset is large and made up of three available personality datasets of various social media platforms including Reddit, Twitter, and Personality Cafe forum. We induce personality embeddings from our transformer-based model and investigate if they can be used for downstream text classification tasks. Experimental evidence shows that personality embeddings are effective in three classification tasks including authorship verification, stance, and hyperpartisan detection. We also provide novel and interpretable analysis for the third task: hyperpartisan news classification. © 2021 Incoma Ltd. All rights reserved.},
	keywords = {Classification (of information); Large dataset; Social networking (online); Text processing; Authorship verification; Classification tasks; Down-stream; Embeddings; Experimental evidence; Multi-labels; Personality traits; Personality types; Social media platforms; User-generated; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Sude2023,
	author = {Sude, Daniel Jeffrey and Sharon, Gil and Dvir-Gvirsman, Shira},
	title = {True, justified, belief? Partisanship weakens the positive effect of news media literacy on fake news detection},
	year = {2023},
	journal = {Frontiers in Psychology},
	volume = {14},
	doi = {10.3389/fpsyg.2023.1242865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173753699&doi=10.3389%2ffpsyg.2023.1242865&partnerID=40&md5=2d100461b79fbc49511bf701fe137941},
	abstract = {To investigate how people assess whether politically consistent news is real or fake, two studies (N = 1,008; N = 1,397) with adult American participants conducted in 2020 and 2022 utilized a within-subjects experimental design to investigate perceptions of news accuracy. When a mock Facebook post with either fake (Study 1) or real (Study 2) news content was attributed to an alternative (vs. a mainstream) news outlet, it was, on average, perceived to be less accurate. Those with beliefs reflecting News Media Literacy demonstrated greater sensitivity to the outlet’s status. This relationship was itself contingent on the strength of the participant’s partisan identity. Strong partisans high in News Media Literacy defended the accuracy of politically consistent content, even while recognizing that an outlet was unfamiliar. These results highlight the fundamental importance of looking at the interaction between user-traits and features of social media news posts when examining learning from political news on social media. Copyright © 2023 Sude, Sharon and Dvir-Gvirsman.},
	author_keywords = {credibility; fake news; journalism; misinformation; online news; social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Sharma2021249,
	author = {Sharma, Srishti and Saraswat, Mala and Dubey, Anil Kumar},
	title = {Fake News Detection Using Deep Learning},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1459 CCIS},
	pages = {249 – 259},
	doi = {10.1007/978-3-030-91305-2_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121614679&doi=10.1007%2f978-3-030-91305-2_19&partnerID=40&md5=ee34cc832cba919b1dd648209f2d1c45},
	abstract = {Owing to the rapid explosion of social networking portals in the past decade, we spread and consume information via the internet at an expeditious rate. It has caused an alarming proliferation of fake news on social networks. The global nature of social networks has facilitated international blowout of fake news. Fake news has proven to increase political polarization and partisan conflict. Fake news is also found to be more rampant on social media than mainstream media. The evil of fake news is garnering a lot of attention and research effort. In this work, we have tried to handle the spread of fake news via tweets. We have performed fake news classification by employing user characteristics as well as tweet text. Thus, trying to provide a holistic solution for fake news detection. For classifying user characteristics, we have used the XGBoost algorithm which is a collaboration of decision trees utilizing the boosting method. Further to correctly classify the tweet text we used various natural language processing techniques to preprocess the tweets and then applied a sequential neural network and state-of-the-art BERT transformer to classify the tweets. The models have then been evaluated and compared with various baseline models to show that our approach effectively tackles this problem. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Classification; Fake news; Gradient boosting; Text classification; Transfer learning; Transformers; Twitter},
	keywords = {Classification (of information); Decision trees; Deep learning; Fake detection; Natural language processing systems; Text processing; Fake news; Gradient boosting; Mainstream media; Research efforts; Social media; Social-networking; Text classification; Transfer learning; Transformer; User characteristics; Social networking (online)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Sánchez-Junquera202141,
	author = {Sánchez-Junquera, Javier},
	title = {On the detection of political and social bias},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {3030},
	pages = {41 – 49},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121306424&partnerID=40&md5=84240c3707c4db38c5c7b6603f35770c},
	abstract = {Nowadays it is very easy to share, create and disseminate any kind of bias thanks to the increasing facilities of the technology. Political and social bias have a lamentable repercussion on the behaviours of people and our life quality. This research is focused on the detection of hyperpartisan news and immigrant stereotypes in political speeches. This work proposes two different explainable approaches: BERT-based models, known for their ability to capture semantic and syntactic patterns in the same representation but at the cost of great computational complexity and lack of transparency; and a masking-based model that has been recognized by its capabilities to deliver good and human-understandable results. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT-based models; Hyperpartisan news; Immigrant stereotypes; Masking technique; Political bias; Social bias},
	keywords = {BERT-based model; Hyperpartisan news; Immigrant stereotype; Life qualities; Masking technique; Political bias; Semantic pattern; Social bias; Syntactic patterns; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Stevanoski20191026,
	author = {Stevanoski, Bozhidar and Gievska, Sonja},
	title = {Team Ned Leeds at SemEval-2019 task 4: Exploring language indicators of hyperpartisan reporting},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1026 – 1031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118597392&partnerID=40&md5=4ec7b35e9dafe8fc5b77cbac765a8015},
	abstract = {This paper reports an experiment carried out to investigate the relevance of several syntactic, stylistic and pragmatic features on the task of distinguishing between mainstream and partisan news articles. The results of the evaluation of different feature sets and the extent to which various feature categories could affect the performance metrics are discussed and compared. Among different combinations of features and classifiers, Random Forest classifier using vector representations of the headline and the text of the report, with the inclusion of 8 readability scores and few stylistic features yielded best result, ranking our team at the 9th place at the SemEval 2019 Hyperpartisan News Detection challenge. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Semantics; Features sets; News articles; Performance metrices; Random forest classifier; Vector representations; Decision trees},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Amason2019967,
	author = {Amason, Evan and Palanker, Jake and Shen, Mary Clare and Medero, Julie},
	title = {Harvey Mudd College at SemEval-2019 task 4: The D.X. Beaumont hyperpartisan news detector},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {967 – 970},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118529322&partnerID=40&md5=ff09ac4eb314852822d067d59b1f96cf},
	abstract = {We use the 600 hand-labelled articles from SemEval Task 4 (Kiesel et al., 2019) to hand-tune a classifier with 3000 features for the Hyperpartisan News Detection task. Our final system uses features based on bag-of-words (BoW), analysis of the article title, language complexity, and simple sentiment analysis in a naive Bayes classifier. We trained our final system on the 600,000 articles labelled by publisher. Our final system has an accuracy of 0.653 on the hand-labeled test set. The most effective features are the Automated Readability Index and the presence of certain words in the title. This suggests that hyperpartisan writing uses a distinct writing style, especially in the title. © 2019 Association for Computational Linguistics},
	keywords = {Classifiers; Semantics; Bag of words; Detection tasks; Feature-based; Harvey mudd colleges; Language complexity; Naive Bayes classifiers; Sentiment analysis; Simple++; System use; Test sets; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kiesel2019829,
	author = {Kiesel, Johannes and Mestre, Maria and Shukla, Rishabh and Vincent, Emmanuel and Adineh, Payam and Corney, David and Stein, Benno and Potthast, Martin},
	title = {SemEval-2019 task 4: Hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {829 – 839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083032765&partnerID=40&md5=993158caf116bbfa0006806a44b7f665},
	abstract = {Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes: no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048. © 2019 Association for Computational Linguistics},
	keywords = {Cloud services; Labeled dataset; Meta information; News articles; Research communities; State of the art},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 139}
}

@ARTICLE{HUANG20211177,
	author = {HUANG, GERALD KI WEI and LEE, JUN CHOI},
	title = {Hyperpartisan news classification with elmo and bias feature},
	year = {2021},
	journal = {Journal of Information Science and Engineering},
	volume = {37},
	number = {5},
	pages = {1177 – 1186},
	doi = {10.6688/JISE.202109_37(5).0013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115976124&doi=10.6688%2fJISE.202109_37%285%29.0013&partnerID=40&md5=6d58a84e596c28218913a9921679c096},
	abstract = {Hyperpartisan news is a kind of news riddled with twisted, untruthful, and often extremely one-sided. This kind of news can spread more successfully than the others. One of the obvious traits of hyperpartisan news content is that it can mimic regular news articles. Most are favour fake news detection algorithms, and there is less research conducted for hyperpartisan news. This research aims to perform classification on the hyperpartisan news using ELMo and bias features. ELMo was used to develop a classification model to perform classification on the BuzzFeed Webis News Corpus dataset. The model uses ELMo embedding with bias word score generated from bias lexicon to train a deep learning model using Tensorflow and Keras. We had compared the final result with two proposed baseline models that utilized ELMo from other research. The discussion section further investigated the contribution of ELMo and bias feature in the hyperpartisan task. © 2021 Institute of Information Science. All rights reserved.},
	author_keywords = {Bias detection; Classification; ELMo; Hyperpartisan; Natural language processing},
	keywords = {Classification (of information); Deep learning; Bias detection; Classification models; Detection algorithm; ELMo; Embeddings; Hyperpartisan; Model use; News articles; News content; News corpora; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cramerus20191021,
	author = {Cramerus, Rebekah and Scheffler, Tatjana},
	title = {Team Kit Kittredge at SemEval-2019 task 4: LSTM voting system},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1021 – 1025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118569817&partnerID=40&md5=8594c7fda8fa9c964375e943fb424b42},
	abstract = {This paper describes the approach of team Kit Kittredge to SemEval 2019 Task 4: Hyperpartisan News Detection. The goal was binary classification of news articles into the categories of “biased” or “unbiased”. We had two software submissions: one a simple bag-of-words model, and the second an LSTM (Long Short Term Memory) neural network, which was trained on a subset of the original dataset selected by a voting system of other LSTMs. This method did not prove much more successful than the baseline, however, due to the models' tendency to learn publisher-specific traits instead of general bias. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Information retrieval; Semantics; Bag-of-words models; Binary classification; Learn+; Neural-networks; News articles; Simple++; Voting systems; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Findlay2018169,
	author = {Findlay, Kyle and van Rensburg, Ockert Janse},
	title = {Using interaction networks to map communities on twitter},
	year = {2018},
	journal = {International Journal of Market Research},
	volume = {60},
	number = {2},
	pages = {169 – 189},
	doi = {10.1177/1470785317753025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055971071&doi=10.1177%2f1470785317753025&partnerID=40&md5=dceed315a6ce9000600ebfbf08ea1f83},
	abstract = {This article summarizes our work using a network-based approach to mapping the main constituencies discussing specific topics on Twitter. The approach gives researchers unique insight into the main groups involved and their agendas. While the individual pieces of the methodology are not new, the way in which we combine them will be novel to many market researchers. By connecting Twitter users that interact with each other into an “interaction network” or “conversation map” and using community detection algorithms to isolate distinct groups, we are able to identify the main constituencies discussing a specific topic such as a national election. Once the main constituencies have been identified, it is possible to profile them in more detail such as in terms of their demographics, their influencers, and the type of content that resonates with them. This article specifically focuses on roughly one million tweets about the 2014 South African national election to illustrate our approach. The authors believe that the approach described has wide-ranging applications and that it can be used to give researchers unprecedented insight into the public discourse surrounding specific topics and events. This article is adapted from an earlier article presented at the 2015 Southern African Marketing Research Association’s (SAMRA) annual conference. © The Author(s) 2018.},
	author_keywords = {Community detection; Community mapping; Constituency mapping; Data-led segmentation; Influencers; Interaction networks; Key opinion leaders (KOL); Media partisanship; Political research; Social media; Social network analysis; South African politics; Twitter},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Patankar2019232,
	author = {Patankar, Anish and Bose, Joy and Khanna, Harshit},
	title = {A Bias Aware News Recommendation System},
	year = {2019},
	journal = {Proceedings - 13th IEEE International Conference on Semantic Computing, ICSC 2019},
	pages = {232 – 238},
	doi = {10.1109/ICOSC.2019.8665610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064119142&doi=10.1109%2fICOSC.2019.8665610&partnerID=40&md5=6091a6f21a6b7c27827e8b45456473da},
	abstract = {In this era of fake news and political polarization, it is desirable to have a system to enable users to access balanced news content. Current solutions focus on top down, server based approaches to decide whether a news article is fake or biased, and display only trusted news to the end users. In this paper, we follow a different approach to help the users make informed choices about which news they want to read, making users aware in real time of the bias in news articles they were browsing and recommending news articles from other sources on the same topic with different levels of bias. We use a recent Pew research report to collect news sources that readers with varying political inclinations prefer to read. We then scrape news articles on a variety of topics from these varied news sources. After this, we perform clustering to find similar topics of the articles, as well as calculate a bias score for each article. For a news article the user is currently reading, we display the bias score and also display other articles on the same topic, out of the previously collected articles, from different news sources. This we present to the user. This approach, we hope, would make it possible for users to access more balanced articles on given news topics. We present the implementation details of the system along with some preliminary results on news articles. © 2019 IEEE.},
	author_keywords = {Bias Detection; Fake News; Recommendation System},
	keywords = {Semantics; Fake News; News articles; News content; News sources; News topics; Real time; Research reports; Server-based; Recommender systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{Ning20191037,
	author = {Ning, Zhiyuan and Lin, Yuanzhen and Zhong, Ruichao},
	title = {Team Peter-Parker at SemEval-2019 task 4: BERT-based method in hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1037 – 1040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118576507&partnerID=40&md5=b1a3ac34fc402876a1adde2c45b00f2c},
	abstract = {This paper describes the team peter-parker's participation in Hyperpartisan News Detection task (SemEval-2019 Task 4), which requires to classify whether a given news article is bias or not. We decided to use Java to do the article parser and the BERT model to do the bias analysis and prediction. Furthermore, we will show experiment results with analysis. © 2019 Association for Computational Linguistics},
	keywords = {Detection tasks; News articles},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chakravartula2019954,
	author = {Chakravartula, Nikhil and Indurthi, Vijayasaradhi and Syed, Bakhtiyar},
	title = {Fermi at SemEval-2019 task 4: The Sarah-Jane-Smith Hyperpartisan news detector},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {954 – 956},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118549369&partnerID=40&md5=bc430fef2bd24f0bc3274ebac2bc2374},
	abstract = {This paper describes our system (Fermi) for Task 4: Hyper-partisan News detection of SemEval-2019. We use simple text classification algorithms by transforming the input features to a reduced feature set. We aim to find the right number of features useful for efficient classification and explore multiple training models to evaluate the performance of these text classification algorithms. Our team - Fermi's model achieved an accuracy of 59.10% and an F1 score of 69.5% on the official test data set. In this paper, we provide a detailed description of the approach as well as the results obtained in the task. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Semantics; Statistical tests; Data set; F1 scores; Features sets; Input features; Performance; Simple++; Test data; Training model; Text processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Maulana2021660,
	author = {Maulana, Ardian and Situngkir, Hokky},
	title = {Media Polarization on Twitter During 2019 Indonesian Election},
	year = {2021},
	journal = {Studies in Computational Intelligence},
	volume = {943},
	pages = {660 – 670},
	doi = {10.1007/978-3-030-65347-7_55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098288056&doi=10.1007%2f978-3-030-65347-7_55&partnerID=40&md5=dc51545e9fbae9e9b6d1a3faf222646c},
	abstract = {In this study, we investigate the phenomenon of political polarization on news consumption patterns of Twitter users during 2019 Indonesian elections. By modeling news consumption as a bipartite network of news outlets-Twitter users, we observed the emergence of a number of media communities based on audience similarity. By measuring political alignments of each news outlet, we reveal the politically fragmented landscape of Indonesian news media, where each media community becomes an political echo-chamber for its audience. Our findings highlight the important role of mainstream media as a bridge of information between political echo-chamber in social media environment. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Community detection; Echo-chamber; Election; Media network; Twitter},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Darwish2022260,
	author = {Darwish, Kareem},
	title = {News Consumption in Time of Conflict: 2021 Palestinian-Israel War as an Example},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {260 – 268},
	doi = {10.1145/3501247.3531568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133674276&doi=10.1145%2f3501247.3531568&partnerID=40&md5=7c5c4511288b3a417596a24e3b2e04b9},
	abstract = {This paper examines news consumption in response to a major polarizing event, and we use the May 2021 Israeli-Palestinian conflict as an example. We conduct a detailed analysis of the news consumption of more than eight thousand Twitter users who are either pro-Palestinian or pro-Israeli and authored more than 29 million tweets between January 1 and August 17, 2021. We identified the stance of users using unsupervised stance detection. We observe that users may consume more topically-related content from foreign and less popular sources, because, unlike popular sources, they may reaffirm their views, offer more extreme, hyper-partisan, or sensational content, or provide more in depth coverage of the event. The sudden popularity of such sources may not translate to longer-term or general popularity on other topics.  © 2022 ACM.},
	author_keywords = {Conflict reporting; media consumption; media popularity},
	keywords = {Conflict reporting; Media consumption; Medium popularity; Related content},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Essa2023,
	author = {Essa, Ehab and Omar, Karima and Alqahtani, Ali},
	title = {Fake news detection based on a hybrid BERT and LightGBM models},
	year = {2023},
	journal = {Complex and Intelligent Systems},
	doi = {10.1007/s40747-023-01098-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160246358&doi=10.1007%2fs40747-023-01098-0&partnerID=40&md5=dc9e470b59b271cba22af6a33de8163b},
	abstract = {With the rapid growth of social networks and technology, knowing what news to believe and what not to believe become a challenge in this digital era. Fake news is defined as provably erroneous information transmitted intending to defraud. This kind of misinformation poses a serious threat to social cohesion and well-being, since it fosters political polarisation and can destabilize trust in the government or the service provided. As a result, fake news detection has emerged as an important field of study, with the goal of identifying whether a certain piece of content is real or fake. In this paper, we propose a novel hybrid fake news detection system that combines a BERT-based (bidirectional encoder representations from transformers) with a light gradient boosting machine (LightGBM) model. We compare the performance of the proposed method to four different classification approaches using different word embedding techniques on three real-world fake news datasets to validate the performance of the proposed method compared to other methods. The proposed method is evaluated to detect fake news based on the headline-only or full text of the news content. The results show the superiority of the proposed method for fake news detection compared to many state-of-the-art methods. © 2023, The Author(s).},
	author_keywords = {BERT; FakeNews; LightGBM; Transformers},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Chen2019957,
	author = {Chen, Celena and Park, Celine and Dwyer, Jason and Medero, Julie},
	title = {Harvey Mudd College at SemEval-2019 task 4: The Carl Kolchak Hyperpartisan News Detector},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {957 – 961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118530519&partnerID=40&md5=b7f94db5e352cc4f216cdb6d1440b9cb},
	abstract = {We use various natural processing and machine learning methods to perform the Hyperpartisan News Detection task. In particular, some of the features we look at are bag-of-words features, the title's length, number of capitalized words in the title, and the sentiment of the sentences and the title. By adding these features, we see improvements in our evaluation metrics compared to the baseline values. We find that sentiment analysis helps improve our evaluation metrics. We do not see a benefit from feature selection. Overall, our system achieves an accuracy of 0.739, finishing 18th out of 42 submissions to the task. From our work, it is evident that both title features and sentiment of articles are meaningful to the hyperpartisanship of news articles. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Learning systems; Semantics; Bag of words; Baseline values; Detection tasks; Evaluation metrics; Features selection; Harvey mudd colleges; Machine learning methods; News articles; Sentiment analysis; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Faragó2023,
	author = {Faragó, Laura and Krekó, Péter and Orosz, Gábor},
	title = {Hungarian, lazy, and biased: the role of analytic thinking and partisanship in fake news discernment on a Hungarian representative sample},
	year = {2023},
	journal = {Scientific Reports},
	volume = {13},
	number = {1},
	doi = {10.1038/s41598-022-26724-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145645578&doi=10.1038%2fs41598-022-26724-8&partnerID=40&md5=bb5624e583aed7035f9493cad2b6bf6c},
	abstract = {“Why do people believe blatantly inaccurate news headlines? Do we use our reasoning abilities to convince ourselves that statements that align with our ideology are true, or does reasoning allow us to effectively differentiate fake from real regardless of political ideology?” These were the questions of Pennycook and Rand (2019), and they are more than actual three years later in Eastern Europe (especially in Hungary) in the light of the rise of populism, and the ongoing war in Ukraine – with the flood of disinformation that follows. In this study, using a representative Hungarian sample (N = 991) we wanted to answer the same questions—moving one step forward and investigating alternative models. We aimed to extend the original research with the examination of digital literacy and source salience on media truth discernment. Most of the observations of Pennycook and Rand were confirmed: people with higher analytic thinking were better at discerning disinformation. However, the results are in line with the synergistic integrative model as partisanship interacted with cognitive reflection: anti-government voters used their analytic capacities to question both concordant and discordant fake news more than pro-government voters. Furthermore, digital literacy increased detection, but source salience did not matter when perceiving disinformation. © 2023, The Author(s).},
	keywords = {Deception; Disinformation; Humans; Hungary; Literacy; Problem Solving; article; disinformation; government; human; human experiment; internet literacy; major clinical study; thinking; deception; Hungary; literacy; problem solving},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kim2023,
	author = {Kim, Kang-Min and Lee, Mingyu and Won, Hyun-Sik and Kim, Min-Ji and Kim, Yeachan and Lee, SangKeun},
	title = {Multi-Stage Prompt Tuning for Political Perspective Detection in Low-Resource Settings},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {10},
	doi = {10.3390/app13106252},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160811831&doi=10.3390%2fapp13106252&partnerID=40&md5=c6397fa1e9d2a05f1aa98ccb670a1ce1},
	abstract = {Political perspective detection in news media—identifying political bias in news articles—is an essential but challenging low-resource task. Prompt-based learning (i.e., discrete prompting and prompt tuning) achieves promising results in low-resource scenarios by adapting a pre-trained model to handle new tasks. However, these approaches suffer performance degradation when the target task involves a textual domain (e.g., a political domain) different from the pre-training task (e.g., masked language modeling on a general corpus). In this paper, we develop a novel multi-stage prompt tuning framework for political perspective detection. Our method involves two sequential stages: a domain- and task-specific prompt tuning stage. In the first stage, we tune the domain-specific prompts based on a masked political phrase prediction (MP3) task to adjust the language model to the political domain. In the second task-specific prompt tuning stage, we only tune task-specific prompts with a frozen language model and domain-specific prompts for downstream tasks. The experimental results demonstrate that our method significantly outperforms fine-tuning (i.e., model tuning) methods and state-of-the-art prompt tuning methods on the SemEval-2019 Task 4: Hyperpartisan News Detection and AllSides datasets. © 2023 by the authors.},
	author_keywords = {political bias detection; pre-trained language model; prompt tuning; prompt-based learning; self-supervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Usher201951,
	author = {Usher, James and Morales, Lucia and Dondio, Pierpaolo},
	title = {BREXIT: A granger causality of twitter political polarisation on the FTSE 100 Index and the Pound},
	year = {2019},
	journal = {Proceedings - IEEE 2nd International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2019},
	pages = {51 – 54},
	doi = {10.1109/AIKE.2019.00017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071504770&doi=10.1109%2fAIKE.2019.00017&partnerID=40&md5=40c0a4b96515aad638dd0bfe80b17578},
	abstract = {BREXIT is the single biggest geopolitical event in British history since WWII. Whilst the political fallout has become a tragicomedy, the political ramifications has had a profound impact on the Pound and the FTSE 100 index. This paper examines Twitter political discourse surrounding the BREXIT withdrawal agreement. In particular we focus on the discussions around four different exit strategies known as 'Norway', 'Article 50', the'Backstop' and 'No Deal' and their effect on the pound and FTSE 100 index from the period of rumblings of the cancellation of the Meaning Vote on December 10th 2018 inclusive of second defeat on the Prime Minister's BREXIT exit strategy on February 14th to February 24th 2019. Our approach focuses on using a Naive Bayes classification algorithm to assess political party and public Twitter sentiment. A Granger causality analysis is then introduced to investigate the hypothesis that BREXIT political and public sentiment, as measured by the twitter sentiment time series, is indicative of changes in the GBP/EUR Fx and FTSE 100 Index. Our results indicate that the accuracy of the 'Article 50' scenario had the single biggest effect on short run dynamics on the FTSE 100 index, additionally the 'Norway' BREXIT strategy has a marginal effect on the FTSE 100 index whilst there was no significant causation to the GBP/EUR Fx. © 2019 IEEE.},
	author_keywords = {Data mining; Stock Market; Twitter sentiment; Web intelligence},
	keywords = {Data mining; Knowledge engineering; Social networking (online); Statistical tests; Time series analysis; Geopolitical events; Granger Causality; Granger causality analysis; Naive Bayes classification algorithm; Political discourse; Political parties; Twitter sentiment; Web intelligence; Financial markets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{Moreno2019981,
	author = {Moreno, Jose G. and Pitarch, Yoann and Pinel-Sauvagnat, Karen and Hubert, Gilles},
	title = {Rouletabille at SemEval-2019 task 4: Neural network baseline for identification of hyperpartisan publishers},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {981 – 984},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101432037&partnerID=40&md5=cd0ca33281546952d20f2732f7e9866b},
	abstract = {This paper describes the Rouletabille participation to the Hyperpartisan News Detection task. We propose the use of different text classification methods for this task. Preliminary experiments using a similar collection used in Potthast et al. (2018) show that neural-based classification methods reach state-of-the art results. Our final submission is composed of a unique run that ranks among all runs at 3/49 position for the by-publisher test dataset and 43/96 for the by-article test dataset in terms of Accuracy. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Semantics; Statistical tests; Text processing; Classification methods; Detection tasks; Neural-networks; State of the art; Text classification methods; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Samoilenko2023,
	author = {Samoilenko, Sergei A. and Cook, John},
	title = {Developing an Ad Hominem typology for classifying climate misinformation},
	year = {2023},
	journal = {Climate Policy},
	doi = {10.1080/14693062.2023.2245792},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167806800&doi=10.1080%2f14693062.2023.2245792&partnerID=40&md5=ade89d4692922952141af47b00f30b81},
	abstract = {Misinformation produced by various interest groups is a significant contributing factor to public confusion about climate policy. Character assassination against climate scientists and policymakers is the most common type of misinformation strategy used by contrarians in climate debates (Coan, T. G., Boussalis, C., Cook, J., & Nanko, M. O. (2021). Computer-assisted classification of contrarian claims about climate change. Scientific Reports, 11(1), 22320). Despite its widespread use, however, character assassination remains understudied by social scientists, especially in the context of climate change. This study adapts Douglas Walton’s (1998. Ad hominem arguments. University of Alabama Press) typology of ‘ad hominem’ attacks–personal attacks targeting an individual’s character, competence, or motives–to misinformation campaigns against the climate community. We developed an original codebook for classifying ad hominem arguments made by climate contrarians. Drawing on a 553-paragraph sample from a corpus from 55 contrarian blogs and 15 conservative think-tank websites published in English between 2008 and 2020, we then determined the relative prominence of each type of attack using a consensus-coding approach. Bias attacks, which entail accusing climate scientists of political partisanship or having an ideological agenda, were the most common form of contrarian ad hominem attack. The dominance of bias attacks can be explained by their strong relevance for scientific credibility. The study found that ad hominem attacks, often with bias and moral attacks clustered together, are the most common combination. The article concludes by discussing the implications of these findings for climate policy and future research. Key Policy Insights: Climate misinformation politicizes climate science, further amplifying ideological conflict and fostering ideological polarization; Climate misinformation campaigns feature a range of different types of ad hominem attacks designed to undermine the credibility of climate scientists; The most common type of ad hominem attack on climate scientists in our sample was bias attacks, which entail accusing climate scientists of political partisanship or of having an ideological agenda; Attacks on the moral character of climate scientists were the only type of ad hominem that increased during the period under study (2008–2020); Different types of ad hominems often appeared together, with the most common combination being bias and moral attacks; Ad hominem attacks on climate scientists are part of misinformation campaigns designed to stall discussion on climate change and delay the implementation of climate policies. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Ad hominem; bias; climate change policies; climate science; misinformation; moral attack},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee20191052,
	author = {Lee, Nayeon and Liu, Zihan and Fung, Pascale},
	title = {Team yeon-zi at SemEval-2019 task 4: Hyperpartisan news detection by de-noising weakly-labeled data},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1052 – 1056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084291759&partnerID=40&md5=fa18afb8000e94fb45b1a9b40b516b1d},
	abstract = {This paper describes our system submitted to SemEval-2019 Task 4: Hyperpartisan News Detection. We focus on removing the inherent noise in the hyperpartisanship dataset from both data-level and model-level by leveraging semi-supervised pseudo-labels and the state-of-the-art BERT model. Our model achieves 75.8% accuracy in the final by-article dataset without ensemble learning. © 2019 Association for Computational Linguistics},
	keywords = {Data level; De-noising; Ensemble learning; Inherent noise; Labeled data; Semi-supervised; State of the art},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Kassas2021,
	author = {Kassas, Bachir and Nayga, Rodolfo M.},
	title = {Promoting higher social distancing and stay-at-home decisions during COVID-19: The underlying conflict between public health and the economy},
	year = {2021},
	journal = {Safety Science},
	volume = {140},
	doi = {10.1016/j.ssci.2021.105300},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105076676&doi=10.1016%2fj.ssci.2021.105300&partnerID=40&md5=f2bd5b3d7de65b4402c2f57a8e39b3ba},
	abstract = {Social distancing and stay-at-home orders were implemented as a quick response to the public health crisis created by COVID-19. However, these measures led to competing concerns for public health versus the wellbeing of the economy during the pandemic. This drove polarized views and attitudes towards these measures in the US that threatened their effectiveness in controlling the spread of infections. Our study addresses this point by investigating uptake of messaging treatments that highlight the health risks of COVID-19. We also investigate how priming economic risk of COVID-19 affects responsiveness to the health information messaging. A sample of 1200 US respondents were randomly assigned to a control and four messaging treatments that included information about risks of COVID-19 on own health, public health, the economy, and combination of public health and the economy, respectively. Our results indicate a significant difference in messaging uptake based on political partisanship. Individuals identifying as Democrats increased their social distancing and stay-at-home decisions in response to all information treatments, contrary to Republicans who showed no significant change in their behavior. Using a latent class analysis model, we classify individuals into three main types (dismissive, amenable, and conscious) that differ in their perceptions of the risks associated with COVID-19. We show that only amenable individuals, who account for approximately 34% of the sample, respond significantly to the messaging treatments. © 2021 Elsevier Ltd},
	author_keywords = {COVID-19; Information framing; Prevention strategies; Social distancing},
	keywords = {Classification (of information); Health risks; Public risks; Risk assessment; Risk perception; COVID-19; Economic risks; Health crisis; Health informations; Information framing; Information treatment; Prevention strategies; Quick response; Social distancing; Wellbeing; adult; Article; behavior change; clinical effectiveness; controlled study; coronavirus disease 2019; decision making; economic aspect; female; health care policy; health hazard; health promotion; home quarantine; human; male; medical information; pandemic; perception; priority journal; public health; risk assessment; social distancing; social participation; United States; Public health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{2019,
	title = {NewsIR 2019 - Proceedings of the 3rd International Workshop on Recent Trends in News Information Retrieval, co-located with 42nd International ACM Conference on Research and Development in Information Retrieval, SIGIR 2019},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070666599&partnerID=40&md5=675872a9972647b52228bdf64c2feeef},
	abstract = {The proceedings contain 12 papers. The topics discussed include: good, neutral or bad - news classification; credibility and transparency of news sources: data collection and feature analysis; the diffusion of fake news through the 'middle media' - contaminated online sphere in Japan; tribalism, political polarization and disinformation; corpus of news articles annotated with article level sentiment; squabble: an efficient, scalable controversy classifier; ontology guided purposive news retrieval and presentation; event detection using images of temporal word patterns; and affect enriched word embeddings for news information retrieval.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tun20236913,
	author = {Tun, Yin Min and Khaing, Myo},
	title = {A large-scale sentiment analysis using political tweets},
	year = {2023},
	journal = {International Journal of Electrical and Computer Engineering},
	volume = {13},
	number = {6},
	pages = {6913 – 6925},
	doi = {10.11591/ijece.v13i6.pp6913-6925},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172903228&doi=10.11591%2fijece.v13i6.pp6913-6925&partnerID=40&md5=e3f22729e87cc209fe23bbe9a61ed9b3},
	abstract = {Twitter has become a key element of political discourse in candidates’ campaigns. The political polarization on Twitter is vital to politicians as it is a popular public medium to analyze and predict public opinion concerning political events. The analysis of the sentiment of political tweet contents mainly depends on the quality of sentiment lexicons. Therefore, it is crucial to create sentiment lexicons of the highest quality. In the proposed system, the domain-specific of the political lexicon is constructed by using the supervised approach to extract extreme political opinions words, and features in tweets. Political multi-class sentiment analysis (PMSA) system on the big data platform is developed to predict the inclination of tweets to infer the results of the elections by conducting the analysis on different political datasets: including the Trump election dataset and the BBC News politics. The comparative analysis is the experimental results which are better political text classification by using the three different models (multinomial naïve Bayes (MNB), decision tree (DT), linear support vector classification (SVC)). In the comparison of three different models, linear SVC has the better performance than the other two techniques. The analytical evaluation results show that the proposed system can be performed with 98% accuracy in linear SVC. © 2023 Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Apache flume; Big data analytic; Machine learning; Sentiment analysis Apache; Social media data; Spark},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Drissi2019962,
	author = {Drissi, Mehdi and Sandoval, Pedro and Ojha, Vivaswat and Medero, Julie},
	title = {Harvey Mudd College at SemEval-2019 task 4: The Clint Buchanan hyperpartisan news detector},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {962 – 966},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098818688&partnerID=40&md5=f0779f67d62bc0b5d0b22a787d0a1d01},
	abstract = {We investigate the recently developed Bidirectional Encoder Representations from Transformers (BERT) model (Devlin et al., 2018) for the hyperpartisan news detection task. Using a subset of hand-labeled articles from SemEval as a validation set, we test the performance of different parameters for BERT models. We find that accuracy from two different BERT models using different proportions of the articles is consistently high, with our best-performing model on the validation set achieving 85% accuracy and the best-performing model on the test set achieving 77%. We further determined that our model exhibits strong consistency, labeling independent slices of the same article identically. Finally, we find that randomizing the order of word pieces dramatically reduces validation accuracy (to approximately 60%), but that shuffling groups of four or more word pieces maintains an accuracy of about 80%, indicating the model mainly gains value from local context. © 2019 Association for Computational Linguistics},
	keywords = {Detection tasks; Different proportions; Gain values; Harvey mudd colleges; Labelings; Performance; Strong consistency; Test sets; Transformer modeling; Validation sets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Aksenov2021121,
	author = {Aksenov, Dmitrii and Bourgonje, Peter and Zaczynska, Karolina and Ostendorff, Malte and Moreno-Schneider, Julián and Rehm, Georg},
	title = {Fine-grained Classification of Political Bias in German News: A Data Set and Initial Experiments},
	year = {2021},
	journal = {WOAH 2021 - 5th Workshop on Online Abuse and Harms, Proceedings of the Workshop},
	pages = {121 – 131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130502864&partnerID=40&md5=a259aec1fd83912c76cf2e04942c0963},
	abstract = {We present a data set consisting of German news articles labeled for political bias on a fivepoint scale in a semi-supervised way. While earlier work on hyperpartisan news detection uses binary classification (i. e., hyperpartisan or not) and English data, we argue for a more fine-grained classification, covering the full political spectrum (i. e., far-left, left, centre, right, far-right) and for extending research to German data. Understanding political bias helps in accurately detecting hate speech and online abuse. We experiment with different classification methods for political bias detection. Their comparatively low performance (a macro-F1 of 43 for our best setup, compared to a macro-F1 of 79 for the binary classification task) underlines the need for more (balanced) data annotated in a fine-grained way.  © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Binary classification; Classification methods; Classification tasks; Data set; Fine grained; News articles; Performance; Semi-supervised; Spectra's; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{da Silva2023569,
	author = {da Silva, Samuel Caetano and Paraboni, Ivandré},
	title = {Politically-oriented information inference from text},
	year = {2023},
	journal = {Journal of Universal Computer Science},
	volume = {29},
	number = {6},
	pages = {569 – 594},
	doi = {10.3897/jucs.96652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166113082&doi=10.3897%2fjucs.96652&partnerID=40&md5=44012982646b679c19447ea0225779a5},
	abstract = {The inference of politically-oriented information from text data is a popular research topic in Natural Language Processing (NLP) at both text- and author-level. In recent years, studies of this kind have been implemented with the aid of text representations ranging from simple count-based models (e.g., bag-of-words) to sequence-based models built from transformers (e.g., BERT). Despite considerable success, however, we may still ask whether results may be improved further by combining these models with additional text representations. To shed light on this issue, the present work describes a series of experiments to compare a number of strategies for political bias and ideology inference from text data using sequence-based BERT models, syntaxand semantics-driven features, and examines which of these representations (or their combinations) improve overall model accuracy. Results suggest that one particular strategy - namely, the combination of BERT language models with syntactic dependencies - significantly outperforms well-known count- and sequence-based text classifiers alike. In particular, the combined model has been found to improve accuracy across all tasks under consideration, outperforming the SemEval hyperpartisan news detection top-performing system by up to 6%, and outperforming the use of BERT alone by up to 21%, making a potentially strong case for the use of heterogeneous text representations in the present tasks. © 2023, IICM. All rights reserved.},
	author_keywords = {Author profiling; Natural language processing; Politically-oriented inference; Sentiment analysis; Text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Shaprin20191012,
	author = {Shaprin, Daniel and da San Martino, Giovanni and Barrón-Cedeño, Alberto and Nakov, Preslav},
	title = {Team JACK RYDER at SemEval-2019 task 4: Using BERT representations for detecting hyperpartisan news},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1012 – 1015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095486893&partnerID=40&md5=d0478524c4a31e7ff3be8cffa96309e7},
	abstract = {We describe the system submitted by the Jack Ryder team to SemEval-2019 Task 4 on Hyperpartisan News Detection. The task asked participants to predict whether a given article is hyperpartisan, i.e., extreme-left or extreme-right. We propose an approach based on BERT with fine-tuning, which was ranked 7th out 28 teams on the distantly supervised dataset, where all articles from a hyperpartisan/non-hyperpartisan news outlet are considered to be hyperpartisan/non-hyperpartisan. On a manually annotated test dataset, where human annotators double-checked the labels, we were ranked 29th out of 42 teams. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Fine tuning; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Gaglani2020285,
	author = {Gaglani, Jaynil and Gandhi, Yash and Gogate, Shubham and Halbe, Aparna},
	title = {Unsupervised WhatsApp Fake News Detection using Semantic Search},
	year = {2020},
	journal = {Proceedings of the International Conference on Intelligent Computing and Control Systems, ICICCS 2020},
	pages = {285 – 289},
	doi = {10.1109/ICICCS48265.2020.9120902},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087451370&doi=10.1109%2fICICCS48265.2020.9120902&partnerID=40&md5=1161c236fdfb027ba64b03ecbc740b88},
	abstract = {Social media has become the backbone of today's lifestyle. It has a widespread effect on nearly every walk of life. One of the well-known social media applications WhatsApp Messenger is a free and cross-platform text messaging software that also provides services for sending and receiving multimedia messages. But at the same time in recent years, its easy accessibility has served a way for propagating fake and biased news articles, blogs and messages. Fake news and messages have paved their way for Political polarization, ethnic tensions, unwanted panic and mass hysteria. A solution is proposed that uses Natural Language Processing for analyzing the messages and leverage Transfer Learning Models to detect the authenticity of the information. Claims are filtered from the bulk of forwarded messages disseminated on WhatsApp. The solution comprises of a semantic search mechanism between each claim and associated news sources. The similarity comparison done by the model predicts the truthfulness of the claim. © 2020 IEEE.},
	author_keywords = {Fake News; Natural Language Processing; Transfer Learning; WhatsApp},
	keywords = {Application programs; Control systems; Intelligent computing; Multimedia services; Natural language processing systems; Semantics; Social networking (online); Text messaging; Transfer learning; Cross-platform; Multimedia messages; NAtural language processing; News articles; News sources; Semantic search; Social media; Semantic Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@CONFERENCE{Bestgen20191062,
	author = {Bestgen, Yves},
	title = {Tintin at SemEval-2019 task 4: Detecting hyperpartisan news article with only simple tokens},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1062 – 1066},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083036661&partnerID=40&md5=3c2bc6ecfa5d97d3a11ad1e05d98d6ec},
	abstract = {Tintin, the system proposed by the CECL for the Hyperpartisan News Detection task of SemEval 2019, is exclusively based on the tokens that make up the documents and a standard supervised learning procedure. It obtained very contrasting results: poor on the main task, but much more effective at distinguishing documents published by hyperpartisan media outlets from unbiased ones, as it ranked first. An analysis of the most important features highlighted the positive aspects, but also some potential limitations of the approach. © 2019 Association for Computational Linguistics},
	keywords = {Detection tasks; Important features; Main tasks; Media outlets; News articles; Simple++},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@BOOK{Agresti2023125,
	author = {Agresti, Stefano and Carman, Mark J.},
	title = {Automated Techniques for Identifying Claims and Assisting Fact Checkers},
	year = {2023},
	journal = {Machine Learning and Deep Learning in Natural Language Processing},
	pages = {125 – 146},
	doi = {10.1201/9781003296126-10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173839247&doi=10.1201%2f9781003296126-10&partnerID=40&md5=168c303d2f4f995eac2054e565b570a3},
	abstract = {A concerning issue of our age is the spread of misinformation online. The dissemination of false, misleading, or biased information can adversely affect society and can threaten democracy by precluding healthy, fact-based political discourse. The circulation of false or distorted news can sow distrust and fear among the public, culminating in the propagation of conspiracy theories. Not only can this exacerbate political partisanship, but also it can make it difficult to enforce unpopular, yet necessary, legislation as seen during the COVID-19 pandemic. While it would be naïve to place all the blame for the spread of such misinformation on social media platforms, it is undeniable that social networks have allowed fake news to prosper as never before. Numerous studies have investigated how best to fight this phenomenon, oftentimes exploiting powerful Artificial Intelligence techniques. Yet, they suffer from a limitation when dealing with such an elusive problem in that they assume a simple dichotomy between real and fake news. In this chapter, we propose a new finer-grained taxonomy for online news content that goes well beyond this binary distinction. We investigate the feasibility of categorizing texts according to this new classification scheme, using datasets extracted from Reddit, and a crowdsourcing-based evaluation. Then based on these classifiers, we prototype a system for assisting journalists with their fact-checking activities, helping them to identify claims in political transcripts and retrieve passages from news articles that may provide evidence supporting or refuting those claims. © 2024 selection and editorial matter, Anitha S. Pillai and Roberto Tedesco.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xiao2023,
	author = {Xiao, Zhiping and Zhu, Jeffrey and Wang, Yining and Zhou, Pei and Lam, Wen Hong and Porter, Mason A. and Sun, Yizhou},
	title = {Detecting political biases of named entities and hashtags on Twitter},
	year = {2023},
	journal = {EPJ Data Science},
	volume = {12},
	number = {1},
	doi = {10.1140/epjds/s13688-023-00386-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161451381&doi=10.1140%2fepjds%2fs13688-023-00386-6&partnerID=40&md5=f018cf2957c5870344345016e7611fc3},
	abstract = {Ideological divisions in the United States have become increasingly prominent in daily communication. Accordingly, there has been much research on political polarization, including many recent efforts that take a computational perspective. By detecting political biases in a text document, one can attempt to discern and describe its polarity. Intuitively, the named entities (i.e., the nouns and the phrases that act as nouns) and hashtags in text often carry information about political views. For example, people who use the term “pro-choice” are likely to be liberal and people who use the term “pro-life” are likely to be conservative. In this paper, we seek to reveal political polarities in social-media text data and to quantify these polarities by explicitly assigning a polarity score to entities and hashtags. Although this idea is straightforward, it is difficult to perform such inference in a trustworthy quantitative way. Key challenges include the small number of known labels, the continuous spectrum of political views, and the preservation of both a polarity score and a polarity-neutral semantic meaning in an embedding vector of words. To attempt to overcome these challenges, we propose the Polarity-aware Embedding Multi-task learning (PEM) model. This model consists of (1) a self-supervised context-preservation task, (2) an attention-based tweet-level polarity-inference task, and (3) an adversarial learning task that promotes independence between an embedding’s polarity component and its semantic component. Our experimental results demonstrate that our PEM model can successfully learn polarity-aware embeddings that perform well at tweet-level and account-level classification tasks. We examine a variety of applications—including a study of spatial and temporal distributions of polarities and a comparison between tweets from Twitter and posts from Parler—and we thereby demonstrate the effectiveness of our PEM model. We also discuss important limitations of our work and encourage caution when applying the PEM model to real-world scenarios. © 2023, The Author(s).},
	author_keywords = {Adversarial training; Data sets; Multi-task learning; Political-polarity detection; Word embeddings},
	keywords = {Natural language processing systems; Semantics; Social networking (online); Adversarial training; Data set; Embeddings; Hashtags; Learning models; Multitask learning; Named entities; Political views; Political-polarity detection; Word embedding; Embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Baly20192109,
	author = {Baly, Ramy and Karadzhov, Georgi and Saleh, Abdelrhman and Glass, James and Nakov, Preslav},
	title = {Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media},
	year = {2019},
	journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	volume = {1},
	pages = {2109 – 2116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070522837&partnerID=40&md5=732f03aa281017b2c5dfeba967a85a2a},
	abstract = {In the context of fake news, bias, and propaganda, we study two important but relatively under-explored problems: (i) trustworthiness estimation (on a 3-point scale) and (ii) political ideology detection (left/right bias on a 7-point scale) of entire news outlets, as opposed to evaluating individual articles. In particular, we propose a multi-task ordinal regression framework that models the two problems jointly. This is motivated by the observation that hyper-partisanship is often linked to low trustworthiness, e.g., appealing to emotions rather than sticking to the facts, while center media tend to be generally more impartial and trustworthy. We further use several auxiliary tasks, modeling centrality, hyper-partisanship, as well as left-vs.-right bias on a coarse-grained scale. The evaluation results show sizable performance gains by the joint models over models that target the problems in isolation. © 2019 Association for Computational Linguistics},
	keywords = {Coarse-grained; Evaluation results; Joint models; News media; Ordinal regression; Performance Gain; Political ideologies; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{de Kock20225601,
	author = {de Kock, Christine and Vlachos, Andreas},
	title = {Leveraging Wikipedia article evolution for promotional tone detection},
	year = {2022},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {5601 – 5613},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149119006&partnerID=40&md5=65cc8b61ec3b372e8d6f4e895623ae54},
	abstract = {Detecting biased language is useful for a variety of applications, such as identifying hyperpartisan news sources or flagging one-sided rhetoric. In this work we introduce WikiEvolve, a dataset for document-level promotional tone detection in English. Unlike previously proposed datasets, it contains seven versions of the same article from Wikipedia, from different points in its revision history; one with promotional tone, and six without it. We adapt the gradient reversal layer framework to encode two article versions simultaneously, and thus leverage the training signal present in the multiple versions. In our experiments, our proposed adaptation of gradient reversal improves the accuracy of four different architectures on both in-domain and out-of-domain evaluation. © 2022 Association for Computational Linguistics.},
	keywords = {News sources; Training signal; Wikipedia; Wikipedia articles},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{de Ghantuz Cubbe2023511,
	author = {de Ghantuz Cubbe, Giovanni},
	title = {I Trends on COVID-19 and Populism},
	year = {2023},
	journal = {International Political Science Abstracts},
	volume = {73},
	number = {4},
	pages = {511 – 521},
	doi = {10.1177/00208345231194168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166653635&doi=10.1177%2f00208345231194168&partnerID=40&md5=243dd1c2e8e45bb90a6cca65e108542d},
	abstract = {The COVID-19 crisis has challenged political and health institutions around the world. Political scientists have been particularly interested in, among several other interconnected issues, the pandemic’s relationship to populism. This trend article provides an up-to-date general classification of the current literature on COVID-19 and populism. In order to systematize the diverse approaches, it divides research into five macro-areas. Finally, it points out the methodologies employed by the literature, the results obtained so far, and the remaining challenges to be analyzed. One of the most significant conclusions is that the politicization of COVID-19 and the high levels of social and political polarization observed during the pandemic strongly affected the responses of different institutions, which led to significant consequences in terms of the relationships between levels of government. © International Political Science Association 2023.},
	author_keywords = {Authoritarianism; Covid-19; Fake News; Federalism; Pandemic; Polarization; Politicization; Populism},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Saleh20191041,
	author = {Saleh, Abdelrhman and Baly, Ramy and Barrón-Cedeño, Alberto and da San Martino, Giovanni and Mohtarami, Mitra and Nakov, Preslav and Glass, James},
	title = {Team QCRI-MIT at SemEval-2019 task 4: Propaganda analysis meets hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1041 – 1046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118555311&partnerID=40&md5=e6047b63b2432068572d1a4a6b0e35db},
	abstract = {We describe our submission to SemEval-2019 Task 4 on Hyperpartisan News Detection. We rely on a variety of engineered features originally used to detect propaganda. This is based on the assumption that biased messages are propagandistic and promote a particular political cause or viewpoint. In particular, we trained a logistic regression model with features ranging from simple bag of words to vocabulary richness and text readability. Our system achieved 72.9% accuracy on the manually annotated testset, and 60.8% on the test data that was obtained with distant supervision. Additional experiments showed that significant performance gains can be achieved with better feature pre-processing. © 2019 Association for Computational Linguistics},
	keywords = {Regression analysis; Additional experiments; Bag of words; Logistic Regression modeling; Performance Gain; Pre-processing; Simple++; Test data; Test sets; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Yeh20191067,
	author = {Yeh, Chia-Lun and Loni, Babak and Schuth, Anne},
	title = {Tom Jumbo-Grumbo at SemEval-2019 task 4: Hyperpartisan news detection with GloVe vectors and SVM},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1067 – 1071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105932901&partnerID=40&md5=9b3672ba35eb7ad6c543bee5d8fb793e},
	abstract = {In this paper, we describe our attempt to learn bias from news articles. From our experiments, it seems that although there is a correlation between publisher bias and article bias, it is challenging to learn bias directly from the publisher labels. On the other hand, using few manually-labeled samples can increase the accuracy metric from around 60% to near 80%. Our system is computationally inexpensive and uses several standard document representations in NLP to train an SVM or LR classifier. The system ranked 4th in the SemEval-2019 task. The code is released for reproducibility. © 2019 Association for Computational Linguistics},
	keywords = {Document Representation; Learn+; News articles; Reproducibilities; Standard documents},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Polyák2022133,
	author = {Polyák, Gábor and Urbán, Ágnes and Szávai, Petra},
	title = {Information Patterns and News Bubbles in Hungary},
	year = {2022},
	journal = {Media and Communication},
	volume = {10},
	number = {3},
	pages = {133 – 145},
	doi = {10.17645/MAC.V10I3.5373},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143623701&doi=10.17645%2fMAC.V10I3.5373&partnerID=40&md5=ac15d0b260aa10439e3fde8d3eb4f5a5},
	abstract = {The study is based on data from a representative survey conducted in Hungary in 2020, which examined the public’s consumption of political and public information. Using the survey data, the authors attempt to map the consumption patterns of the Hungarian audience, with a special focus on the relationship between party preferences and the consumption of the various news sources with different ideological backgrounds. The research aims to better understand the phenomenon of polarisation, which is increasingly observed on both the supply and demand sides of the Hungarian news media. The focus of the study is to examine news consumption patterns in Hungary and the relationship between political polarisation and news consumption. The authors analysed the prevalence of information bubbles in the Hungarian public sphere, where consumers are only exposed to the views of one political side without being confronted with information or opinions that differ. Particular attention is paid to a special category of the Hungarian media system, the grey‐zone media; they might seem to contribute greatly to the pluralism of the media system, but they are, in fact, strongly politically dependent. In addi-tion to the identified news consumption patterns, the study aims to shed light on the importance and problematic nature of this grey‐zone media category and to reveal how deeply the Hungarian public is actually dependent on the government. © 2022 by the author(s); licensee Cogitatio (Lisbon, Portugal).},
	author_keywords = {Hungarian media; information bubble; media classification; news consumption; polarisation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hrckova2022954,
	author = {Hrckova, Andrea and Moro, Robert and Srba, Ivan and Bielikova, Maria},
	title = {Quantitative and qualitative analysis of linking patterns of mainstream and partisan online news media in Central Europe},
	year = {2022},
	journal = {Online Information Review},
	volume = {46},
	number = {5},
	pages = {954 – 973},
	doi = {10.1108/OIR-10-2020-0441},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120500826&doi=10.1108%2fOIR-10-2020-0441&partnerID=40&md5=889344e80a6e4cd183367bbbc3555264},
	abstract = {Purpose: Partisan news media, which often publish extremely biased, one-sided or even false news, are gaining popularity world-wide and represent a major societal issue. Due to a growing number of such media, a need for automatic detection approaches is of high demand. Automatic detection relies on various indicators (e.g. content characteristics) to identify new partisan media candidates and to predict their level of partisanship. The aim of the research is to investigate to a deeper extent whether it would be appropriate to rely on the hyperlinks as possible indicators for better automatic partisan news media detection. Design/methodology/approach: The authors utilized hyperlink network analysis to study the hyperlinks of partisan and mainstream media. The dataset involved the hyperlinks of 18 mainstream media and 15 partisan media in Slovakia and Czech Republic. More than 171 million domain pairs of inbound and outbound hyperlinks of selected online news media were collected with Ahrefs tool, analyzed and visualized with Gephi software. Additionally, 300 articles covering COVID-19 from both types of media were selected for content analysis of hyperlinks to verify the reliability of quantitative analysis and to provide more detailed analysis. Findings: The authors conclude that hyperlinks are reliable indicators of media affinity and linking patterns could contribute to partisan news detection. The authors found out that especially the incoming links with dofollow attribute to news websites are reliable indicators for assessing the type of media, as partisan media rarely receive links with dofollow attribute from mainstream media. The outgoing links are not such reliable indicators as both mainstream and partisan media link to mainstream sources similarly. Originality/value: In contrast to the extensive amount of research aiming at fake news detection within a piece of text or multimedia content (e.g. news articles, social media posts), the authors shift to characterization of the whole news media. In addition, the authors did a geographical shift from more researched US-based media to so far under-researched European context, particularly Central Europe. The results and conclusions can serve as a guide how to derive new features for an automatic detection of possibly partisan news media by means of artificial intelligence (AI). Peer review: The peer review history for this article is available at the following link: https://publons.com/publon/10.1108/OIR-10-2020-0441. © 2021, Emerald Publishing Limited.},
	author_keywords = {Central Europe; Content analysis; COVID-19; Hyperlink network analysis; Media profiling; Partisan online news media},
	keywords = {Reliability analysis; Websites; Central Europe; Content analysis; COVID-19; Hyperlink network analyse; Hyperlink networks; Hyperlinks; Medium profiling; News media; Online news; Partisan online news medium; Hypertext systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Wei2020258,
	author = {Wei, Jason and Santos, Eugene},
	title = {Narrative origin classification of israeli-palestinian conflict texts},
	year = {2020},
	journal = {Proceedings of the 33rd International Florida Artificial Intelligence Research Society Conference, FLAIRS 2020},
	pages = {258 – 263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102414297&partnerID=40&md5=340043873bcba078cc470ad7d1315a2e},
	abstract = {The Israeli-Palestinian conflict is one of the most controversial in history. Not surprisingly, historic and contemporary literature on the topic tends to be polarized. Drawing inspiration from work in political ideology and hyperpartisan news detection, we collect two new datasets of history book excerpts and newspaper articles regarding the Israeli-Palestinian conflict and train sequence classifiers to predict whether a text is written by an Israeli or Palestinian source. Moreover, we find that data augmentation techniques improve performance, allowing our best model to detect narrative origin with an F1 score of 85.1% for history book excerpts and 91.9% for newspaper articles. Analysis of indicative phrases discovered by our models corroborate historian insight regarding the conflict. © FLAIRS 2020.All right reserved.},
	keywords = {Classification (of information); History; Newsprint; Best model; Data augmentation; F1 scores; History books; Improve performance; Political ideologies; Artificial intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Alzhrani2022731,
	author = {Alzhrani, Khudran M.},
	title = {Politicians-based Deep Learning Models for Detecting News, Authors and Media Political Ideology},
	year = {2022},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {13},
	number = {2},
	pages = {731 – 742},
	doi = {10.14569/IJACSA.2022.0130286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126124032&doi=10.14569%2fIJACSA.2022.0130286&partnerID=40&md5=18a358767549869172a169db55b9e8e4},
	abstract = {Non-partisanship is one of the qualities that contribute to journalistic objectivity. Factual reporting alone cannot combat political polarization in the news media. News framing, agenda settings, and priming are influence mechanisms that lead to political polarization, but they are hard to identify. This paper attempts to automate the detection of two political science concepts in news coverage: politician personalization and political ideology. Politicians’ news coverage personalization is a concept that encompasses one more of the influence mechanisms. Political ideologies are often associated with controversial topics such as abortion and health insurance. However, the paper prove that politicians’ personalization is related to the political ideology of the news articles. Constructing deep neural network models based on politicians’ personalization improved the performance of political ideology detection models. Also, deep networks models could predict news articles’ politician personalization with a high F1 score. Despite being trained on less data, personalizedbased deep networks proved to be more capable of capturing the ideology of news articles than other non-personalized models. The dataset consists of two politician personalization labels, namely Obama and Trump, and two political ideology labels, Democrat and Republican. The results showed that politicians’ personalization and political polarization exist in news articles, authors, and media sources. © 2022, (IJACSA) International Journal of Advanced Computer Science and Applications. All Rights Reserved.},
	author_keywords = {Deep neural networks; Political ideology; Politician personalization; Text classification},
	keywords = {Classification (of information); Health insurance; Polarization; Text processing; Agenda settings; Influence mechanism; Learning models; News articles; News coverage; News media; Personalizations; Political ideologies; Politician personalization; Text classification; Deep neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Cruz2019999,
	author = {Cruz, André Ferreira and Rocha, Gil and Sousa-Silva, Rui and Cardoso, Henrique Lopes},
	title = {Team Fernando-Pessa at SemEval-2019 task 4: Back to basics in hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {999 – 1003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083027921&partnerID=40&md5=dfab89edba9e37e598756c2f38e175eb},
	abstract = {This paper describes our submission1 to the SemEval 2019 Hyperpartisan News Detection task. Our system aims for a linguistics-based document classification from a minimal set of interpretable features, while maintaining good performance. To this goal, we follow a feature-based approach and perform several experiments with different machine learning classifiers. On the main task, our model achieved an accuracy of 71.7%, which was improved after the task's end to 72.9%. We also participate in the meta-learning sub-task, for classifying documents with the binary classifications of all submitted systems as input, achieving an accuracy of 89.9%. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Information retrieval systems; Learning systems; Binary classification; Detection tasks; Document Classification; Feature based approaches; Main tasks; Metalearning; Performance; Subtask; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Jiang2019840,
	author = {Jiang, Ye and Petrak, Johann and Song, Xingyi and Bontcheva, Kalina and Maynard, Diana},
	title = {Team Bertha von Suttner at SemEval-2019 task 4: Hyperpartisan news detection using ELMo sentence representation convolutional network},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {840 – 844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038399&partnerID=40&md5=2c5a784ba62023b6f7e6bf6a45b00dd0},
	abstract = {This paper describes the participation of team “bertha-von-suttner” in the SemEval2019 task 4 Hyperpartisan News Detection task. Our system1 uses sentence representations from averaged word embeddings generated from the pre-trained ELMo model with Convolutional Neural Networks and Batch Normalization for predicting hyperpartisan news. The final predictions were generated from the averaged predictions of an ensemble of models. With this architecture, our system ranked in first place, based on accuracy, the official scoring metric. © 2019 Association for Computational Linguistics},
	keywords = {Convolution; Convolutional neural networks; Semantics; Convolutional networks; Convolutional neural network; Detection tasks; Embeddings; Ensemble of models; Normalisation; Place-based; Scoring metrics; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@CONFERENCE{Cruz2020892,
	author = {Cruz, André Ferreira and Rocha, Gil and Cardoso, Henrique Lopes},
	title = {On document representations for detection of biased news articles},
	year = {2020},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {892 – 899},
	doi = {10.1145/3341105.3374025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083035044&doi=10.1145%2f3341105.3374025&partnerID=40&md5=f64dea3a63625a4d3f09d69eab03af8e},
	abstract = {Detecting bias in text is an increasingly relevant topic, given the information overload problem. Automating this task is crucial for our needs of quality news consumption. With this in mind, we explore modern deep learning approaches, including contextualized word embeddings and attention mechanisms, to compare the effects of different document representation choices. We design token-wise, sentence-wise and hierarchical document representations. Focusing on hyperpartisan news detection, we show that hierarchical attention mechanisms are able to better capture information at different levels of granularity (including intra and inter-sentence), which seems to be relevant for this task. With an accuracy of 82.5%, our best performing system is based on an ensemble of hierarchical attention networks with ELMo embeddings, achieving state-of-the-art performance on the SemEval-2019 Task4 dataset. © 2020 ACM.},
	author_keywords = {Bias detection; Deep learning; Document representation; Hyperpartisan news; Natural language processing},
	keywords = {Embeddings; Attention mechanisms; Document Representation; Hierarchical document; Information overloads; Learning approach; News articles; State-of-the-art performance; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Hanawa20191057,
	author = {Hanawa, Kazuaki and Sasaki, Shota and Ouchi, Hiroki and Suzuki, Jun and Inui, Kentaro},
	title = {The Sally Smedley Hyperpartisan News Detector at SemEval-2019 task 4: Learning classifiers with feature combinations and ensembling},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1057 – 1061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038275&partnerID=40&md5=6210065e6a12aed9f8648389ad1882f8},
	abstract = {This paper describes our system submitted to the formal run of SemEval-2019 Task 4: Hyperpartisan news detection. Our system is based on a linear classifier using several features, i.e., 1) embedding features based on the pre-trained BERT embeddings, 2) article length features, and 3) embedding features of informative phrases extracted from the by-publisher dataset. Our system achieved 80.9% accuracy on the test set for the formal run and got the 3rd place out of 42 teams. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Semantics; Embeddings; Feature combination; Feature-based; Learning classifiers; Linear classifiers; Test sets; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Zehe20191047,
	author = {Zehe, Albin and Hettinger, Lena and Ernst, Stefan and Hauptmann, Christian and Hotho, Andreas},
	title = {Team Xenophilius Lovegood at SemEval-2019 task 4: Hyperpartisanship classification using convolutional neural networks},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1047 – 1051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118542511&partnerID=40&md5=77305c7005873282c45d5672f1075bd1},
	abstract = {This paper describes our system for the SemEval 2019 Task 4 on hyperpartisan news detection. We build on an existing deep learning approach for sentence classification based on a Convolutional Neural Network. Modifying the original model with additional layers to increase its expressiveness and finally building an ensemble of multiple versions of the model, we obtain an accuracy of 67.52 % and an F1 score of 73.78 % on the main test dataset. We also report on additional experiments incorporating handcrafted features into the CNN and using it as a feature extractor for a linear SVM. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Semantics; Statistical tests; Support vector machines; Additional experiments; Convolutional neural network; F1 scores; Feature extractor; Learning approach; Linear SVM; Original model; Sentence classifications; Convolution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Shephard2023,
	author = {Shephard, Mark P. and Robertson, David J. and Huhe, Narisong and Anderson, Anthony},
	title = {Everyday non-partisan fake news: Sharing behavior, platform specificity, and detection},
	year = {2023},
	journal = {Frontiers in Psychology},
	volume = {14},
	doi = {10.3389/fpsyg.2023.1118407},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160808576&doi=10.3389%2ffpsyg.2023.1118407&partnerID=40&md5=82fc50b02694a57b8e23cf20fe6c48b7},
	abstract = {Concern over the impact of fake news on major socio-political events is growing. The use of deliberate misinformation is thought to have played a role in the outcome of the UK EU referendum, the 2016 US presidential election, and in the effectiveness of COVID-19 public health messaging. As a result, recent research has tended to focus on hyper-partisan (e.g., US politics; Democrat/Republican), person specific (e.g., Hillary Clinton/Donald Trump) content that incorporates emotive and hyperbolic language. However, in this study, we focus on an alternative form of fake news, across a variety of topics (e.g., Crime, Immigration, and Health), that avoids these characteristics, and which may therefore be more pervasive and difficult to detect. In a three-part study, we examined participants sharing intentions for fake news (including platform preference; Facebook, Twitter, Instagram, and WhatsApp), their ability to explicitly detect fake news, and whether individual differences on psychological measures of critical thinking ability, rational thinking, and emotional stability predict sharing behavior and detection ability. The results show that even our well-informed sample (political science students) were not immune to the effects of fake news, some issues (e.g., health and crime) were more likely to be shared than others (e.g., immigration), and on specific platforms (e.g., Twitter, Facebook). In addition, we show that individual differences in emotional stability appears to be a key factor in sharing behavior, while rational thinking aptitude was key to fake news detection. Taken together, this study provides novel data that can be used to support targeted fake news interventions, suggesting possible news topic, sharing behavior, and platform specific insights. Such interventions, and implications for government policy, education, and social media companies are discussed. Copyright © 2023 Shephard, Robertson, Huhe and Anderson.},
	author_keywords = {fake news; individual differences; news sharing; news sharing platform; social media},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Pérez-Almendros2019929,
	author = {Pérez-Almendros, Carla and Espinosa-Anke, Luis and Schockaert, Steven},
	title = {Cardiff University at SemEval-2019 task 4: Linguistic features for hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {929 – 933},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118590845&partnerID=40&md5=bfcf3b667c1a0ce14b433fceaa43017a},
	abstract = {This paper summarizes our contribution to the Hyperpartisan News Detection task in SemEval 2019. We experiment with two different approaches: 1) an SVM classifier based on word vector averages and hand-crafted linguistic features, and 2) a BiLSTM-based neural text classifier trained on a filtered training set. Surprisingly, despite their different nature, both approaches achieve an accuracy of 0.74. The main focus of this paper is to further analyze the remarkable fact that a simple feature-based approach can perform on par with modern neural classifiers. We also highlight the effectiveness of our filtering strategy for training the neural network on a large but noisy training set. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Support vector machines; Cardiff; Detection tasks; Feature based approaches; Linguistic features; Neural classifiers; Simple++; SVM classifiers; Text classifiers; Training sets; Word vectors; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sousa-Silva20222409,
	author = {Sousa-Silva, Rui},
	title = {Fighting the Fake: A Forensic Linguistic Analysis to Fake News Detection},
	year = {2022},
	journal = {International Journal for the Semiotics of Law},
	volume = {35},
	number = {6},
	pages = {2409 – 2433},
	doi = {10.1007/s11196-022-09901-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129037593&doi=10.1007%2fs11196-022-09901-w&partnerID=40&md5=85ed03a5e5aaf7acce3fe6c12b18be12},
	abstract = {Fake news has been the focus of debate, especially since the election of Donald Trump (2016), and remains a topic of concern in democratic countries worldwide, given (a) their threat to democratic systems and (b) the difficulty in detecting them. Despite the deployment of sophisticated computational systems to identify fake news, as well as the streamlining of fact-checking methods, appropriate fake news detection mechanisms have not yet been found. In fact, technological approaches are likely to be inefficient, given that fake news are based mostly on partisanship and identity politics, and not necessarily on outright deception. However, as disinformation is inherently expressed linguistically, this is a privileged room for forensic linguistic analysis. This article builds upon a forensic linguistic analysis of fake news pieces published in English and in Portuguese, which were collected since 2019 from acknowledged fake news outlets. The preliminary empirical analysis reveals that fake news pieces employ particular linguistic features, e.g. at the levels of typography, orthography and spelling, and morphosyntax. The systematic identification of these features, which will allow mapping linguistic resources and patterns used in those contexts, contributes to scholarship, not only by enabling a streamlined development of computational detection systems, but more importantly by permitting the forensic linguistics expert to assist criminal investigations and give evidence in court. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Cybercrime; Disinformation; Fact-checking; Fake news; Forensic linguistics; Language crimes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Beauvais2022,
	author = {Beauvais, Catherine},
	title = {Fake news: Why do we believe it?},
	year = {2022},
	journal = {Joint Bone Spine},
	volume = {89},
	number = {4},
	doi = {10.1016/j.jbspin.2022.105371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131434379&doi=10.1016%2fj.jbspin.2022.105371&partnerID=40&md5=4f4d8efbf3304d828811aa09920d36f0},
	abstract = {Fake news dissemination has increased greatly in recent years, with peaks during the US presidential elections and the COVID-19 pandemic. Research has addressed fake news creation, consumption, sharing, and detection as well as approaches to counteract it and prevent people from believing it. This update addresses only a part of the fake news-related issues and focuses on determinants leading individuals to believe fake news, noting that rheumatology is scarcely represented. Some determinants relate to the ecosystem of media and social networks, such as the availability and rapid spread of fake news, the unselected information on platforms and the fact that consumers can become creators of fake news. Cognitive factors are important, such as confirmation bias, political partisanship, prior exposure and intuitive thinking. Low science knowledge and low educational level are also involved. Psychological factors include attraction to novelty, high emotional state, and the emotionally evocative content of fake news. High digital literacy protects against believing fake news. Sociological factors such as online communities, or echo chambers, and the role of pressure groups have been identified. The implication for practice can be deduced, including education in media literacy and warning tips, reliable journalism and fact-checking, social media regulation, partnership of media platforms’ with fact-checkers, warning messages on networks, and digital detection solutions. Health professionals need to better understand the factors that cause individuals to believe fake news. Identifying these determinants may help them in their counseling role when talking to patients about misinformation. © 2022 Société française de rhumatologie},
	author_keywords = {Cognitive bias; Fake news; Misinformation; Social networks},
	keywords = {COVID-19; Disinformation; Ecosystem; Humans; Pandemics; Social Media; advocacy group; altruism; confirmation bias; confusion (uncertainty); consumer; critical thinking; disinformation; education; emotion; emotional intelligence; health belief; health literacy; human; illusory correlation; impulsiveness; information dissemination; information seeking; Internet; internet literacy; intuition; journalism; knowledge; media literacy; misinformation; online social network; political participation; psychological aspect; reasoning; rheumatology; science; Short Survey; social media; social network; socialization; tertiary education; ecosystem; pandemic; prevention and control; social media},
	type = {Short survey},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Zhang20224129,
	author = {Zhang, Wenqian and Feng, Shangbin and Chen, Zilong and Lei, Zhenyu and Li, Jundong and Luo, Minnan},
	title = {KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {4129 – 4140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136156444&partnerID=40&md5=7cf1088d23c7dfa3ae8fc8fe07a17edc},
	abstract = {Political perspective detection has become an increasingly important task that can help combat echo chambers and political polarization. Previous approaches generally focus on leveraging textual content to identify stances, while they fail to reason with background knowledge or leverage the rich semantic and syntactic textual labels in news articles. In light of these limitations, we propose KCD, a political perspective detection approach to enable multi-hop knowledge reasoning and incorporate textual cues as paragraph-level labels. Specifically, we firstly generate random walks on external knowledge graphs and infuse them with news text representations. We then construct a heterogeneous information network to jointly model news content as well as semantic, syntactic and entity cues in news articles. Finally, we adopt relational graph neural networks for graph-level representation learning and conduct political perspective detection. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods on two benchmark datasets. We further examine the effect of knowledge walks and textual cues and how they contribute to our approach's data efficiency. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph neural networks; Information services; Knowledge graph; Knowledge management; Syntactics; Background knowledge; Detection approach; Knowledge reasoning; Multi-hops; News articles; News media; Political perspective; Random Walk; Textual content; Textual labels; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Huang201929,
	author = {Huang, Gerald Ki Wei and Lee, Jun Choi},
	title = {Hyperpartisan news and articles detection using BERT and ELMo},
	year = {2019},
	journal = {Proceedings - 2019 International Conference on Computer and Drone Applications, IConDA 2019},
	pages = {29 – 32},
	doi = {10.1109/IConDA47345.2019.9034917},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083028514&doi=10.1109%2fIConDA47345.2019.9034917&partnerID=40&md5=18978bbc050794218fb0c0639a6337e1},
	abstract = {Fake news and articles are misleading the readers. This leads to the increasing studies of fake news article detection over the decades. Hyperpartisan news is news riddled with twisted and untruth and extremely one-sided. This news can spread more successfully than others. Besides that, hyperpartisan news can mimic the form of regular news articles. This study aims to identify and classify the hyperpartisan news with BERT and ELMo. Two distinct models, BERT and ELMo, were created to classify hyperpartisan news from two datasets, namely by-article and by-publisher. Few other models with different settings and training designed to test and optimise the performance of both models. The results of the optimised BERT and ELMo models can achieve 68.4% and 60.8%, respectively. © 2019 IEEE.},
	author_keywords = {Classification; Hyperpartisan; Natural Language Processing},
	keywords = {Drones; News articles; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@ARTICLE{Saleh2021129471,
	author = {Saleh, Hager and Alharbi, Abdullah and Alsamhi, Saeed Hamood},
	title = {OPCNN-FAKE: Optimized Convolutional Neural Network for Fake News Detection},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {129471 – 129489},
	doi = {10.1109/ACCESS.2021.3112806},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115150924&doi=10.1109%2fACCESS.2021.3112806&partnerID=40&md5=569b0fe305f8ab57899629b9ff3d167d},
	abstract = {Recently, there is a rapid and wide increase in fake news, defined as provably incorrect information spread with the goal of fraud. The spread of this type of misinformation is a severe danger to social cohesiveness and well-being since it increases political polarisation and people's distrust of their leaders. Thus, fake news is a phenomenon that is having a significant impact on our social lives, particularly in politics. This paper proposes novel approaches based on Machine Learning (ML) and Deep Learning (DL) for the fake news detection system to address this phenomenon. The main aim of this paper is to find the optimal model that obtains high accuracy performance. Therefore, we propose an optimized Convolutional Neural Network model to detect fake news (OPCNN-FAKE). We compare the performance of the OPCNN-FAKE with Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and The six regular ML techniques: Decision Tree (DT), logistic Regression (LR), K Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB) using four fake news benchmark datasets. Grid search and hyperopt optimization techniques have been used to optimize the parameters of ML and DL, respectively. In addition, N-gram and Term Frequency - Inverse Document Frequency (TF-IDF) have been used to extract features from the benchmark datasets for regular ML, while Glove word embedding has been used to represent features as a feature matrix for DL models. To evaluate the performance of the OPCNN-FAKE, accuracy, precision, recall, F1-measure were applied to validate the results. The results show that OPCNN-FAKE model has achieved the best performance for each dataset compared with other models. Furthermore, the OPCNN-FAKE has a higher performance of cross-validation results and testing results over the other models, which indicates that the OPCNN-FAKE for fake news detection is significantly better than the other models.  © 2013 IEEE.},
	author_keywords = {convolutional neural network; deep learning; detection; Fake news; machine learning; neural network; OPCNN-FAKE},
	keywords = {Barium compounds; Benchmarking; Convolution; Convolutional neural networks; Decision trees; Deep learning; Inverse problems; Logistic regression; Nearest neighbor search; Support vector machines; Support vector regression; Text processing; Benchmark datasets; Cross validation; Detection system; Feature matrices; Inverse Document Frequency; K nearest neighbor (KNN); Optimization techniques; Recurrent neural network (RNN); Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48; All Open Access, Gold Open Access}
}

@ARTICLE{Shi2022,
	author = {Shi, Hanyu and Silva, Mirela and Giovanini, Luiz and Capecci, Daniel and Czech, Lauren and Fernandes, Juliana and Oliveira, Daniela},
	title = {Lumen: A machine learning framework to expose influence cues in texts},
	year = {2022},
	journal = {Frontiers in Computer Science},
	volume = {4},
	doi = {10.3389/fcomp.2022.929515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138436474&doi=10.3389%2ffcomp.2022.929515&partnerID=40&md5=2f73944829037a61ca34f0a248eecf2b},
	abstract = {Phishing and disinformation are popular social engineering attacks with attackers invariably applying influence cues in texts to make them more appealing to users. We introduce Lumen, a learning-based framework that exposes influence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv) objectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was trained with a newly developed dataset of 3K texts comprised of disinformation, phishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in comparison to other learning models showed that Lumen and LSTM presented the best F1-micro score, but Lumen yielded better interpretability. Our results highlight the promise of ML to expose influence cues in text, toward the goal of application in automatic labeling tools to improve the accuracy of human-based detection and reduce the likelihood of users falling for deceptive online content. Copyright © 2022 Shi, Silva, Giovanini, Capecci, Czech, Fernandes and Oliveira.},
	author_keywords = {dataset; deception; disinformation; media analysis; misinformation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Shrestha2020261,
	author = {Shrestha, Anu and Spezzano, Francesca and Gurunathan, Indhumathi},
	title = {Multi-modal Analysis of Misleading Political News},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12259 LNCS},
	pages = {261 – 276},
	doi = {10.1007/978-3-030-61841-4_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096418037&doi=10.1007%2f978-3-030-61841-4_18&partnerID=40&md5=fdd87b0764128f2ed1e4237f2d966a9a},
	abstract = {The internet is a valuable resource to openly share information or opinions. Unfortunately, such internet openness has also made it increasingly easy to abuse these platforms through the dissemination of misinformation. As people are generally awash in information, they can sometimes have difficulty discerning misinformation propagated on these web platforms from truthful information. They may also lean too heavily on information providers or social media platforms to curate information even though such providers do not commonly validate sources. In this paper, we focus on political news and present an analysis of misleading news according to different modalities, including news content (headline, body, and associated image) and source bias. Our findings show that hyperpartisan news sources are more likely to spread misleading stories than other sources and that it is not necessary to read news body content to assess its validity, but considering other modalities such as headlines, visual content, and publisher bias can achieve better performances. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Misinformation detection on the web; Multi-modal content analysis; Source bias},
	keywords = {Artificial intelligence; Computer science; Computers; Information provider; News content; News sources; Political news; Social media platforms; Visual content; Modal analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Naredla2022,
	author = {Naredla, Navakanth Reddy and Adedoyin, Festus Fatai},
	title = {Detection of hyperpartisan news articles using natural language processing technique},
	year = {2022},
	journal = {International Journal of Information Management Data Insights},
	volume = {2},
	number = {1},
	doi = {10.1016/j.jjimei.2022.100064},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126573366&doi=10.1016%2fj.jjimei.2022.100064&partnerID=40&md5=5b0c176890d3b6b85098b0602faaae6d},
	abstract = {Yellow journalism has increased the spread of hyperpartisan news on the internet. It is very difficult for online news article readers to distinguish hyperpartisan news articles from mainstream news articles. There is a need for an automated model that can detect hyperpartisan news on the internet and tag them as hyperpartisan so that it is very easy for readers to avoid that news. A hyperpartisan news detection article was developed by using three different natural language processing techniques named BERT, ELMo, and Word2vec. This research used the bi-article dataset published at SEMEVAL-2019. The ELMo word embeddings which are trained on a Random forest classifier has got an accuracy of 0.88, which is much better than other state of art models. The BERT and Word2vec models have got the same accuracy of 0.83. This research tried different sentence input lengths to BERT and proved that BERT can extract context from local words. Evidenced from the described ML models, this study will assist the governments, news’ readers, and other political stakeholders to detect any hyperpartisan news, and also helps policy to track, and regulate, misinformation about the political parties and their leaders. © 2022 The Author(s)},
	author_keywords = {BERT; Bidirectional; ELMo; NLP; Tensorflow; Transformers; Word embedding's; Word2vec},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@CONFERENCE{Papadopoulou2019924,
	author = {Papadopoulou, Olga and Kordopatis-Zilos, Giorgos and Zampoglou, Markos and Papadopoulos, Symeon and Kompatsiaris, Yiannis},
	title = {Brenda Starr at SemEval-2019 task 4: Hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {924 – 928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118560616&partnerID=40&md5=357346b59dca19012dd09a1154d085a2},
	abstract = {In the effort to tackle the challenge of Hyperpartisan News Detection, i.e., the task of deciding whether a news article is biased towards one party, faction, cause, or person, we experimented with two systems: i) a standard supervised learning approach using superficial text and bag-of-words features from the article title and body, and ii) a deep learning system comprising a four-layer convolutional neural network and max-pooling layers after the embedding layer, feeding the consolidated features to a bi-directional recurrent neural network. We achieved an F-score of 0.712 with our best approach, which corresponds to the mid-range of performance levels in the leaderboard. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Multilayer neural networks; Network layers; Semantics; Bag of words; Bi-directional; Convolutional neural network; Embeddings; F-score; Max-pooling; News articles; Performance:level; Supervised learning approaches; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Peters2022,
	author = {Peters, Uwe},
	title = {Algorithmic Political Bias Can Reduce Political Polarization},
	year = {2022},
	journal = {Philosophy and Technology},
	volume = {35},
	number = {3},
	doi = {10.1007/s13347-022-00576-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137034570&doi=10.1007%2fs13347-022-00576-6&partnerID=40&md5=bf89e17938f73187a8b051ead26ce401},
	abstract = {Does algorithmic political bias contribute to an entrenchment and polarization of political positions? Franke (Philosophy and Technology, 35, 7, 2022) argues that it may do so because the bias involves classifications of people as liberals, conservatives, etc., and individuals often conform to the ways in which they are classified. I provide a novel example of this phenomenon in human–computer interactions and introduce a social psychological mechanism (what I shall call ‘implied political labeling’) that has been overlooked in this context but should be experimentally explored. Furthermore, while Franke proposes that algorithmic political classifications entrench political identities, I contend that they may often produce the opposite result. They can lead people to change in ways that disconfirm the classifications (thus causing ‘looping effects’). Consequently and counterintuitively, algorithmic political bias can in fact decrease political entrenchment and polarization. © 2022, The Author(s).},
	author_keywords = {Algorithmic political bias; Looping effects; Political entrenchment; Political polarization},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gupta2019934,
	author = {Gupta, Viresh and Jolly, Baani Leen Kaur and Kaur, Ramneek and Chakraborty, Tanmoy},
	title = {Clark Kent at SemEval-2019 task 4: Stylometric insights into hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {934 – 938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098824819&partnerID=40&md5=7d3c6151b2920b90dd0af6d50af3ee3a},
	abstract = {In this paper, we present a news bias prediction system, which we developed as part of a SemEval 2019 task. We developed an XGBoost based system which uses character and word level n-gram features represented using TF-IDF, count vector based correlation matrix, and predicts if an input news article is a hyperpartisan news article. Our model was able to achieve a precision of 68.3% on the test set provided by the contest organizers. We also run our model on the BuzzFeed corpus and find XGBoost with simple character level N-Gram embeddings to be performing well with an accuracy of around 96%. © 2019 Association for Computational Linguistics},
	keywords = {Character level; Correlation matrix; Embeddings; N-grams; News articles; Prediction systems; Simple++; Stylometrics; Test sets; Word level; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Horne2019,
	author = {Horne, Benjamin D. and NØrregaard, Jeppe and Adali, Sibel},
	title = {Robust fake news detection over time and attack},
	year = {2019},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	volume = {11},
	number = {1},
	doi = {10.1145/3363818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077367010&doi=10.1145%2f3363818&partnerID=40&md5=ff2c4901b28e59cc2cd1f7320e1086b7},
	abstract = {In this study, we examine the impact of time on state-of-the-art news veracity classifiers. We show that, as time progresses, classification performance for both unreliable and hyper-partisan news classification slowly degrade. While this degradation does happen, it happens slower than expected, illustrating that hand-crafted, content-based features, such as style of writing, are fairly robust to changes in the news cycle.We show that this small degradation can bemitigated using online learning. Last, we examine the impact of adversarial content manipulation by malicious news producers. Specifically, we test three types of attack based on changes in the input space and data availability. We show that static models are susceptible to content manipulation attacks, but online models can recover from such attacks. © 2019 Association for Computing Machinery.},
	author_keywords = {Adversarial machine learning; Biased news; Concept drift; Disinformation; Fake news; Fake news detection; Misinformation; Misleading news; Robust machine learning},
	keywords = {Biased news; Concept drifts; Disinformation; Fake news; Misinformation; Misleading news; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@ARTICLE{Wozniak2021960,
	author = {Wozniak, Kevin H. and Drakulich, Kevin M. and Calfano, Brian R.},
	title = {Public Opinion About Police Weapons and Equipment: An Exploratory Analysis},
	year = {2021},
	journal = {Criminal Justice Policy Review},
	volume = {32},
	number = {9},
	pages = {960 – 991},
	doi = {10.1177/08874034211005005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103418166&doi=10.1177%2f08874034211005005&partnerID=40&md5=da5194464516ec1023f0a96001d44dc8},
	abstract = {Despite debates about the “material militarization” of the police, relatively little information on mass public opinion about police weapons, equipment, and gear currently exists. We analyze data from a national, opt-in panel of survey participants to assess public opinion regarding police use of 10 different types of weapons and equipment for use in confrontations with citizens. We find that public opinion defies easy classification into “militarized” versus “routine” equipment categories. Multivariate analyses indicate that perceptions of (a) police efficacy and (b) the frequency with which officers experience physical assaults on the job are the most consistent predictors of support for a range of weapons and gear, whereas perceptions of police misconduct and bias predict opposition to some types of tools. Partisan differences in attitudes between Democrats, Republicans, and Independents are less consistent predictors than broader perceptions about policing, but the effects of partisanship that are evident are substantively large. © The Author(s) 2021.},
	author_keywords = {militarization; police; politics; public opinion; weapons},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Albanese2023,
	author = {Albanese, Federico and Feuerstein, Esteban and Lombardi, Leandro and Balenzuela, Pablo},
	title = {Characterizing community-changing users using text mining and graph machine learning on Twitter},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162886865&partnerID=40&md5=a049722b70eaef0ec05872fca4c9b685},
	abstract = {Even though the Internet and social media have increased the amount of news and information people can consume, most users are only exposed to content that reinforces their positions and isolates them from other ideological communities. This environment has real consequences with great impact on our lives like severe political polarization, easy spread of fake news, political extremism, hate groups and the lack of enriching debates, among others. Therefore, encouraging conversations between different groups of users and breaking the closed community is of importance for healthy societies. In this paper, we characterize and study users who change their community on Twitter using natural language processing techniques and graph machine learning algorithms. In particular, we collected 9 million Twitter messages from 1.5 million users and constructed retweet networks. We identified their communities and topics of discussion associated with them. With this data, we present a machine learning framework for social media users classification which detects users that swing from their closed community to another one. A feature importance analysis in three Twitter polarized political datasets showed that these users have low values of PageRank, suggesting that changes in community are driven because their messages have no resonance in their original communities. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {communities; graph learning; Social Media; text mining},
	keywords = {Data mining; Fake detection; Learning algorithms; Natural language processing systems; Social networking (online); Community; Community IS; Exposed to; Graph learning; Graph machine; Internet media; Machine-learning; Mining machines; Social media; Text-mining; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Srivastava20191078,
	author = {Srivastava, Vertika and Sahoo, Sudeep Kumar and Gupta, Ankita and Rohit, R.R. and Prakash, Divya and Kim, Yeon Hyang},
	title = {Vernon-fenwick at SemEval-2019 task 4: Hyperpartisan news detection using lexical and semantic features},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1078 – 1082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083026422&partnerID=40&md5=39507acd1bf13f2f9140016630c20edf},
	abstract = {In this paper, we present our submission for SemEval-2019 Task 4: Hyperpartisan News Detection. Hyperpartisan news articles are sharply polarized and extremely biased (one-sided). It shows blind beliefs, opinions and unreasonable adherence to a party, idea, faction or a person. Through this task, we aim to develop an automated system that can be used to detect hyperpartisan news and serve as a prescreening technique for fake news detection. The proposed system jointly uses a rich set of handcrafted textual and semantic features. Our system achieved 2nd rank on the primary metric (82.0% accuracy) and 1st rank on the secondary metric (82.1% F1-score), among all participating teams. Comparison with the best performing system on the leaderboard1 shows that our system is behind by only 0.2% absolute difference in accuracy. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Absolute difference; Automated systems; F1 scores; Lexical features; News articles; Participating teams; Prescreening; Semantic features; Textual features; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Reilly202359,
	author = {Reilly, Thom and Hunting, Dan},
	title = {The fluid voter: Exploring independent voting patterns over time},
	year = {2023},
	journal = {Politics and Policy},
	volume = {51},
	number = {1},
	pages = {59 – 80},
	doi = {10.1111/polp.12517},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147008342&doi=10.1111%2fpolp.12517&partnerID=40&md5=b07656a2c9e9f391bba36a066e8d295c},
	abstract = {Independents remain hard to categorize because they are, by their choice of self-identification, resisting the standard categories of political classification. Despite the growth in independent voter identity, many political strategists still view independents as partisans. In this article, we contribute to the academic literature on independent voting behavior by exploring whether those who identify as politically independent function as true independents by accounting for their voting patterns over time. We do this by analyzing data produced by the American National Election Studies (ANES) on political identification and voting choices from 1972 to 2020 on each of the three ANES measures of party affiliation. Our findings show when tracking independent voting behavior over more than one election, there is a significant volatility in voting loyalty and independents as a group are distinct from partisans. This volatility was observed in all three measures of party affiliation used by the ANES survey data. The research also finds evidence that a sizeable number of independents move in and out of independent status from one election to another. Related Articles: Grossmann, Matt. 2014. “The Varied Effects of Policy Cues on Partisan Opinions.” Politics & Policy 42(6): 881–904. https://doi.org/10.1111/polp.12102. Reilly, Thom, and E. C. Hedberg. 2022. “Social Networks of Independents and Partisans: Are Independents a Moderating Forcer?” Politics & Policy 50(2): 225–43. https://doi.org/10.1111/polp.12460. Saeki, Manabu. 2019. “Anatomy of Party Sorting: Partisan Polarization of Voters and Party Switching.” Politics & Policy 47(4): 699–747. https://doi.org/10.1111/polp.12318. © 2023 Policy Studies Organization.},
	author_keywords = {ANES; elections; fluid voter; independent voter; over time; partisanship; political behavior; political parties; United States; volatility; voter identification; voting behavior; voting loyalty},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Guilbeault2021,
	author = {Guilbeault, Douglas and Woolley, Samuel and Becker, Joshua},
	title = {Probabilistic social learning improves the public’s judgments of news veracity},
	year = {2021},
	journal = {PLoS ONE},
	volume = {16},
	number = {3 March},
	doi = {10.1371/journal.pone.0247487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102658613&doi=10.1371%2fjournal.pone.0247487&partnerID=40&md5=825f71e615b1949ae262333e82fac54d},
	abstract = {The digital spread of misinformation is one of the leading threats to democracy, public health, and the global economy. Popular strategies for mitigating misinformation include crowdsourcing, machine learning, and media literacy programs that require social media users to classify news in binary terms as either true or false. However, research on peer influence suggests that framing decisions in binary terms can amplify judgment errors and limit social learning, whereas framing decisions in probabilistic terms can reliably improve judgments. In this preregistered experiment, we compare online peer networks that collaboratively evaluated the veracity of news by communicating either binary or probabilistic judgments. Exchanging probabilistic estimates of news veracity substantially improved individual and group judgments, with the effect of eliminating polarization in news evaluation. By contrast, exchanging binary classifications reduced social learning and maintained polarization. The benefits of probabilistic social learning are robust to participants’ education, gender, race, income, religion, and partisanship. © 2021 Guilbeault et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Adult; Communication; Crowdsourcing; Female; Humans; Judgment; Male; Models, Statistical; Politics; Public Health; Social Interaction; Social Learning; Social Media; United States; adult; article; binary classification; crowdsourcing; decision making; democracy; education; female; gender; human; human experiment; male; media literacy; misinformation; peer pressure; polarization; public health; race; religion; social learning; social media; interpersonal communication; politics; social interaction; social media; statistical model; United States},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Joo2019990,
	author = {Joo, Youngjun and Hwang, Inchon},
	title = {Steve Martin at SemEval-2019 task 4: Ensemble learning model for detecting hyperpartisan news},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {990 – 994},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091900275&partnerID=40&md5=14a238159bef9c61b55ecdb6c79bb24d},
	abstract = {This paper describes our submission to task 4 in SemEval 2019, i.e., hyperpartisan news detection. Our model aims at detecting hyperpartisan news by incorporating the style-based features and the content-based features. We extract a broad number of feature sets and use as our learning algorithms the GBDT and the n-gram CNN model. Finally, we apply the weighted average for effective learning between the two models. Our model achieves an accuracy of 0.745 on the test set in subtask A. © 2019 Association for Computational Linguistics},
	keywords = {Learning algorithms; Semantics; CNN models; Content-based features; Effective learning; Ensemble learning; Features sets; Learning models; N-grams; Subtask; Test sets; Weighted averages; Learning systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Machado20191013,
	author = {Machado, Caio and Kira, Beatriz and Narayanan, Vidya and Kollanyi, Bence and Howard, Philip N.},
	title = {A study of misinformation in whatsapp groups with a focus on the brazilian presidential elections},
	year = {2019},
	journal = {The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019},
	pages = {1013 – 1019},
	doi = {10.1145/3308560.3316738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066887935&doi=10.1145%2f3308560.3316738&partnerID=40&md5=ae8551927deb068b31a8b111699aaef0},
	abstract = {There are rising concerns over the spread of misinformation in WhatsApp groups and the potential impact on political polarization, hindrance of public debate and fostering acts of political violence. As social media use becomes increasingly widespread, it becomes imperative to study how these platforms can be used to as a tool to spread propaganda and manipulate audience groups ahead of important political events. In this paper, we present a grounded typology to classify links to news sources into different categories including 'junk' news sources that deliberately publish or aggregate misleading, deceptive or incorrect information packaged as real news about politics, economics or culture obtained from public WhatsApp groups. Further, we examine a sample of 200 videos and images, extracted from a sample of WhatsApp groups and develop a new typology to classify this media content. For our analysis, we have used data from 130 public WhatsApp groups in the period leading up to the two rounds of the 2018 Brazilian presidential elections. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.},
	author_keywords = {Brazilian Elections; Misinformation; Typology; WhatsApp},
	keywords = {World Wide Web; Brazilian Elections; Misinformation; Political events; Political violence; Potential impacts; Presidential election; Typology; WhatsApp; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49}
}

@ARTICLE{Clementson2023,
	author = {Clementson, David E. and Zhao, Wenqing},
	title = {When a journalist and politician engage in deception detection: Effects of demeanor, refutation, and partisanship in combative media interviews},
	year = {2023},
	journal = {Communication Monographs},
	doi = {10.1080/03637751.2023.2244030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168650042&doi=10.1080%2f03637751.2023.2244030&partnerID=40&md5=ad73fed8be0c7e6ffcd3809296e58d08},
	abstract = {When journalists accuse politicians of deception and politicians return fire, how do voters decide what to believe? Grounded on truth-default theory and visual primacy theory, this paper reports experiments with stimuli of interviews in which a journalist accuses a politician of deceptive evasion. In Study 1, we manipulate whether the journalist’s allegation is accurate. Voters seem unable to tell, basing their perceptions on the politician’s demeanor. In Study 2 we test the effect of a politician honestly refuting a dishonest journalist. Voters still attend to demeanor, not verbal message content. In Study 3 partisanship, verbal refutation, and nonverbal demeanor interact. Democratic voters respond more favorably to their politician refuting a journalist and are not misled by demeanor like Republicans. © 2023 National Communication Association.},
	author_keywords = {Deception detection; Demeanor; Partisan bias; Political interview; Truth-default theory; Visual primacy},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2021,
	title = {WASSA 2021 - Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Proceedings of the 11th Workshop},
	year = {2021},
	journal = {WASSA 2021 - Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, Proceedings of the 11th Workshop},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138756919&partnerID=40&md5=37427af7cd143d197524b826445dbada},
	abstract = {The proceedings contain 30 papers. The topics discussed include: language that captivates the audience: predicting affective ratings of TED talks in a multi-label classification task; partisanship and fear are associated with resistance to COVID-19 directives; explainable detection of sarcasm in social media; emotion ratings: how intensity, annotation confidence and agreements are entangled; disentangling document topic and author gender in multiple languages: lessons for adversarial debiasing; universal joy a data set and results for classifying emotions across languages; FEEL-IT: emotion and sentiment classification for the Italian language; an end-to-end network for emotion-cause pair extraction; WASSA 2021 shared task: predicting empathy and emotion in reaction to news stories; and WASSA@IITK at WASSA 2021: multi-task learning and transformer finetuning for emotion classification and empathy prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Miller2022,
	author = {Miller, Stacy and Menard, Philip and Bourrie, David and Sittig, Scott},
	title = {Integrating truth bias and elaboration likelihood to understand how political polarisation impacts disinformation engagement on social media},
	year = {2022},
	journal = {Information Systems Journal},
	doi = {10.1111/isj.12418},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142876618&doi=10.1111%2fisj.12418&partnerID=40&md5=df9d3d69ccc21c391e7c84485b3be3ea},
	abstract = {Political polarisation has become an increasingly alarming issue in society, exacerbated by the widespread use of social media and the development of filter bubbles among social media users. This environment has left users susceptible to disinformation, especially those with whom a user is politically aligned. In this research, we integrate truth bias, elaboration likelihood model and new media literacy into a model for explaining social media engagement (with both disinformation and factual information) and analysing how political polarisation (operationalised as political alignment between users) influences perceptions and behaviours. Using an experimental design, we analyse the model separately for posts containing disinformation and factual information, highlighting key differences. Political alignment positively moderates truth bias's effect on engagement with disinformation. For both disinformation and factual information, political alignment moderates the effect of generalised communicative suspicion (GCS) on truth bias, such that GCS's effect on truth bias flips from negative to positive as political alignment increases. Issue involvement and political alignment appear to be the primary drivers of disinformation engagement, with critical consuming media literacy failing to mitigate engagement. Our findings contribute to the understanding of persuasion, conviction, amplification, polarisation and aversion related to fake news on social media. © 2022 John Wiley & Sons Ltd.},
	author_keywords = {disinformation; elaboration likelihood; fake news; media literacy; polarisation; political orientation; truth bias},
	keywords = {Alignment; Fake detection; Social networking (online); Disinformation; Elaboration likelihood; Elaboration likelihood models; Factual information; Fake news; Medium literacy; New media; Political orientation; Social media; Truth bias; Polarization},
	type = {Conference paper},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Isbister2019939,
	author = {Isbister, Tim and Johansson, Fredrik},
	title = {Dick-Preston and Morbo at SemEval-2019 task 4: Transfer learning for hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {939 – 943},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089224552&partnerID=40&md5=91e69742eef35a2a00c23e219d34d82a},
	abstract = {In a world of information operations, influence campaigns, and fake news, classification of news articles as following hyperpartisan argumentation or not is becoming increasingly important. We present a deep learning-based approach in which a pre-trained language model has been fine-tuned on domain-specific data and used for classification of news articles, as part of the SemEval-2019 task on hyperpartisan news detection. The suggested approach yields accuracy and F1-scores around 0.8 which places the best performing classifier among the top-5 systems in the competition. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Deep learning; Semantics; Domain specific; F1 scores; Information operations; Language model; Learning-based approach; News articles; Preston; Transfer learning; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Clementson2018407,
	author = {Clementson, David E.},
	title = {Truth Bias and Partisan Bias in Political Deception Detection},
	year = {2018},
	journal = {Journal of Language and Social Psychology},
	volume = {37},
	number = {4},
	pages = {407 – 430},
	doi = {10.1177/0261927X17744004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042346942&doi=10.1177%2f0261927X17744004&partnerID=40&md5=154a987d9f5d1de2d40892b917cc6fd7},
	abstract = {This study tests the effects of political partisanship on voters’ perception and detection of deception. Based on social identity theory, in-group members should consider their politician’s message truthful while the opposing out-group would consider the message deceptive. Truth-default theory predicts that a salient in-group would be susceptible to deception from their in-group politician. In an experiment, partisan voters in the United States (N = 618) watched a news interview in which a politician was labeled Democratic or Republican. The politician either answered all the questions or deceptively evaded a question. Results indicated that the truth bias largely prevailed. Voters were more likely to be accurate in their detection when the politician answered and did not dodge. Truth-default theory appears robust in a political setting, as truth bias holds (as opposed to deception bias). Accuracy in detection also depends on group affiliation. In-groups are accurate when their politician answers, and inaccurate when he dodges. Out-groups are more accurate than in-groups when a politician dodges, but still exhibit truth bias. © The Author(s) 2017.},
	author_keywords = {deception detection; political news interview; social identity theory; truth-default theory},
	keywords = {article; controlled study; deception; human; interview; major clinical study; male; perception; public figure; social status; United States},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@ARTICLE{Maulana2021651,
	author = {Maulana, Ardian and Situngkir, Hokky},
	title = {Media Partisanship During Election: Indonesian Cases},
	year = {2021},
	journal = {Studies in Computational Intelligence},
	volume = {943},
	pages = {651 – 659},
	doi = {10.1007/978-3-030-65347-7_54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098254256&doi=10.1007%2f978-3-030-65347-7_54&partnerID=40&md5=71e357e0de5d85a56c7fd6ee8cf602ec},
	abstract = {Analysis of media partisanship during election requires an objective measurement of political bias that frames the content of information conveyed to the audience. In this study, we propose a method for political stance detection of online news outlets based on the behavior of their audience in social media. The method consists of 3 processing stages, namely hashtag-based user labeling, network-based user labeling, and media classification. Evaluation results show that the proposed method is very effective in detecting the political affiliation of Twitter users as well as predicting the political stance of news media. Overall, the stance of media in the spectrum of political valence confirms the general allegations of media partisanship during the 2019 Indonesian election. Further elaboration regarding news consumption behavior shows that low-credibility news outlets tend to have extreme political positions, while partisan readers tend not to question the credibility of the news sources they share. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Label propagation algorithm; Media network; Media partisanship; Twitter},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Palić2019995,
	author = {Palić, Niko and Vladika, Juraj and Čubelić, Dominik and Lovrenčić, Ivan and Buljan, Maja and Šnajder, Jan},
	title = {TakeLab at SemEval-2019 task 4: Hyperpartisan news detection},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {995 – 998},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117560123&partnerID=40&md5=e3382f90fbfc92edb78e6ffdd948020e},
	abstract = {In this paper, we demonstrate the system built to solve the SemEval-2019 task 4: Hyperpartisan News Detection (Kiesel et al., 2019), the task of automatically determining whether an article is heavily biased towards one side of the political spectrum. Our system receives an article in its raw, textual form, analyzes it, and predicts with moderate accuracy whether the article is hyperpartisan. The learning model used was primarily trained on a manually prelabeled dataset containing news articles. The system relies on the previously constructed SVM model, available in the Python Scikit-Learn library. We ranked 6th in the competition of 42 teams with an accuracy of 79.1% (the winning team had 82.2%). © 2019 Association for Computational Linguistics},
	keywords = {Semantics; Support vector machines; Form analysis; Learn+; Learning models; News articles; Spectra's; SVM model; Python},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Jiang20202054,
	author = {Jiang, Ye and Wang, Yimin and Song, Xingyi and Maynard, Diana},
	title = {Comparing topic-aware neural networks for bias detection of news},
	year = {2020},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {325},
	pages = {2054 – 2061},
	doi = {10.3233/FAIA200327},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091737977&doi=10.3233%2fFAIA200327&partnerID=40&md5=fd2d0a48da7eed8bfed352cce7aca740},
	abstract = {The commercial pressure on media has increasingly dominated the institutional rules of news media, and consequently, more and more sensational and dramatized frames and biases are in evidence in newspaper articles. Increased bias in the news media, which can result in misunderstanding and misuse of facts, leads to polarized opinions which can heavily influence the perspectives of the reader. This paper investigates learning models for detecting bias in the news. First, we look at incorporating into the models Latent Dirichlet Allocation (LDA) distributions which could enrich the feature space by adding word co-occurrence distribution and local topic probability in each document. In our proposed models, the LDA distributions are regarded as additive features on the sentence level and document level respectively. Second, we compare the performance of different popular neural network architectures incorporating these LDA distributions on a hyperpartisan newspaper article detection task. Preliminary experiment results show that the hierarchical models benefit more than non-hierarchical models when incorporating LDA features, and the former also outperform the latter. © 2020 The authors and IOS Press.},
	keywords = {Hierarchical systems; Network architecture; Newsprint; Probability distributions; Statistics; Commercial pressure; Detection tasks; Hierarchical model; Institutional rules; Latent dirichlet allocations; Learning models; Sentence level; Word co-occurrence; Neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Anthonio20191016,
	author = {Anthonio, Talita and Kloppenburg, Lennart},
	title = {Team Kermit-the-frog at SemEval-2019 task 4: Bias detection through sentiment analysis and simple linguistic features},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1016 – 1020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118549579&partnerID=40&md5=66c3a328135fa331b64bb62f0a340c66},
	abstract = {In this paper we describe our participation in the SemEval 2019 shared task on hyperpartisan news detection. We present the system that we submitted for final evaluation and the three approaches that we used: sentiment, bias-laden words and filtered n-gram features. Our submitted model is a Linear SVM that solely relies on the negative sentiment of a document. We achieved an accuracy of 0.621 and a f1 score of 0.694 in the competition, revealing the predictive power of negative sentiment for this task. There was no major improvement by adding or substituting the features of the other two approaches that we tried. © 2019 Association for Computational Linguistics},
	keywords = {Semantics; F1 scores; Linear SVM; Linguistic features; N-grams; Negative sentiments; Predictive power; Sentiment analysis; Simple++; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Koshkin201992,
	author = {Koshkin, Pavel G.},
	title = {Think tanks: Challenges and opportunities in the era of "fake news" and digital technologies},
	year = {2019},
	journal = {World Economy and International Relations},
	volume = {63},
	number = {7},
	pages = {92 – 101},
	doi = {10.20542/0131-2227-2019-63-7-92-101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069451188&doi=10.20542%2f0131-2227-2019-63-7-92-101&partnerID=40&md5=38b7ba5d062d9bf9cea29b00f987d29a},
	abstract = {The article deals with the key challenges of Russian and Western think tanks in the era of digital technologies. It presents a detailed and comprehensive classification of analytical centers and shows how they have been developing historically and politically since the 20th century. The author pays attention to the problem of independence of academic and political expertise in the times of information wars, digital illiteracy and dissemination of fake news. In addition, the author compares Russian and Western think tanks, reveals their main differences, systematizes their problems and proposes several original ways of resolving these challenges facing the academic community both in Russia and the U.S. today. The article's relevance is explained with the fact that today nobody, even experts and academics, are immune to fake news and "disruptive technologies", with their ideas and expertise frequently taken out of context and used in the goal of manipulation, as exemplified by the case of The Brookings Institution and The Atlantic Council in February 2017. Moreover, the lack of demand of academic expertise in political circles during Donald Trump's presidency, the plight of Russia Studies programs and International Relations schools in the U.S. as well as partisanship within think tanks only aggravate the problem of today's ideas industry. But all this makes this article more timely and relevant. Its novelty adds up to the fact that the author uses the systemic and comprehensive approach to resolve the problems of Russian and American think tanks in the era of fake news and digital technologies. In particular, it is offered to focus on the roots of the problems (not their implications) by diversifying and streamlining the sources of think tanks funding, turning "disruptive technologies" into new opportunities and creative tools to restore credibility of political and academic expertise, make it better, more effective, educative, objective and independent. © 2019 Russian Academy of Sciences.},
	author_keywords = {Digital revolution; Digital technologies; Fake news; Ideas industry; International relations; Media; Political science; Public diplomacy; Social media; Think tanks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Mutlu20191007,
	author = {Mutlu, Osman and Can, Ozan Arkan and Dayanık, Erenay},
	title = {Team Howard Beale at SemEval-2019 task 4: Hyperpartisan news detection with BERT},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {1007 – 1011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118547951&partnerID=40&md5=a747cd892ee8906a2403f0ba002a6db7},
	abstract = {This paper describes our system for SemEval-2019 Task 4: Hyperpartisan News Detection (Kiesel et al., 2019). We use pretrained BERT (Devlin et al., 2018) architecture and investigate the effect of different fine tuning regimes on the final classification task. We show that additional pretraining on news domain improves the performance on the Hyperpartisan News Detection task. Our system1 ranked 8th out of 42 teams with 78.3% accuracy on the held-out test dataset. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Semantics; Classification tasks; Detection tasks; Fine tuning; News domain; Performance; Pre-training; Statistical tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Agerri2019944,
	author = {Agerri, Rodrigo},
	title = {Doris Martin at SemEval-2019 task 4: Hyperpartisan news detection with generic semi-supervised features},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {944 – 948},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101486062&partnerID=40&md5=962537f1823c1ddad05581c84a7944a5},
	abstract = {In this paper we describe our participation to the Hyperpartisan News Detection shared task at SemEval 2019. Motivated by the late arrival of Doris Martin, we test a previously developed document classification system which consists of a combination of clustering features implemented on top of some simple shallow local features. We show how leveraging distributional features obtained from large in-domain unlabeled data helps to easily and quickly develop a reasonably good performing system for detecting hyperpartisan news. The system and models generated for this task are publicly available. © 2019 Association for Computational Linguistics},
	keywords = {Classification (of information); Computational linguistics; Information retrieval systems; Semantics; Clustering feature; Distributional features; Document classification systems; Late arrival; Local feature; Semi-supervised; Simple++; Unlabeled data; Feature extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Knauth2019976,
	author = {Knauth, Jürgen},
	title = {Orwellian-times at SemEval-2019 task 4: A stylistic and content-based classifier},
	year = {2019},
	journal = {NAACL HLT 2019 - International Workshop on Semantic Evaluation, SemEval 2019, Proceedings of the 13th Workshop},
	pages = {976 – 980},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118576533&partnerID=40&md5=efeee55b4e36426e8715af17550716c7},
	abstract = {While fake news detection received quite a bit of attention in recent years, hyperpartisan news detection is still an underresearched topic. This paper presents our work towards building a classification system for hyperpartisan news detection in the context of the SemEval2019 shared task 4. We experiment with two different approaches - a more stylistic one, and a more content related one - achieving average results. © 2019 Association for Computational Linguistics},
	keywords = {Classification system; Content-based classifiers; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ross2021484,
	author = {Ross, Robert M. and Rand, David G. and Pennycook, Gordon},
	title = {Beyond “fake news”: Analytic thinking and the detection of false and hyperpartisan news headlines},
	year = {2021},
	journal = {Judgment and Decision Making},
	volume = {16},
	number = {2},
	pages = {484 – 504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104024577&partnerID=40&md5=c9148f7a886472f22fc42d8f852fc489},
	abstract = {Why is misleading partisan content believed and shared? An influential account posits that political partisanship pervasively biases reasoning, such that engaging in analytic thinking exacerbates motivated reasoning and, in turn, the acceptance of hyper- partisan content. Alternatively, it may be that susceptibility to hyperpartisan content is explained by a lack of reasoning. Across two studies using different participant pools (total N = 1,973 Americans), we had participants assess true, false, and hyperpartisan news headlines taken from social media. We found no evidence that analytic thinking was associated with judging politically consistent hyperpartisan or false headlines to be accurate and unbiased. Instead, analytic thinking was, in most cases, associated with an increased tendency to distinguish true headlines from both false and hyperpar- tisan headlines (and was never associated with decreased discernment). These results suggest that reasoning typically helps people differentiate between low and high qual- ity political news, rather than facilitate belief in misleading content. Because social media play an important role in the dissemination of misinformation, we also inves- tigated willingness to share headlines on social media. We found a similar pattern whereby analytic thinking was not generally associated with increased willingness to share hyperpartisan or false headlines. Together, these results suggest a positive role for reasoning in resisting misinformation. © 2021, Society for Judgment and Decision making. All rights reserved.},
	author_keywords = {Dual-process theory; Fake news; Misinformation; News media; Partisanship},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@ARTICLE{Misra2022213,
	author = {Misra, Rishabh and Grover, Jigyasa},
	title = {Do Not ‘Fake It Till You Make It’! Synopsis of Trending Fake News Detection Methodologies Using Deep Learning},
	year = {2022},
	journal = {Studies in Big Data},
	volume = {113},
	pages = {213 – 235},
	doi = {10.1007/978-3-031-10869-3_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138673674&doi=10.1007%2f978-3-031-10869-3_12&partnerID=40&md5=8e6069251d169a08e3937013ac26804d},
	abstract = {The modern bloom of social media has propelled a new pattern of information propagation termed push journalism, where a certain piece of news is shoved in the faces of as many people as possible with a sliver of hope that it will reach the people who need that information the most. This form of news reporting, especially via social media campaigns has boosted the access and fabrication of bogus reporting, or what is referred to as fake news. Fake news, in the form of clickbait, hoax, satire, propaganda, hyperpartisan, deepfakes, or simply unreliable news has the power of influencing its readers to a dangerous extent, predominantly causing political, socio-economic, or psychological harm. In this chapter, we analyze the meaning of fake news in the world of social media, the various forms it can take, what causes its spread, and what are the rudimentary signs of such fake news. We will walk through a comparative study of the state-of-the-art deep learning models to approach the tasks of identifying phony information, verifying the validity of various claims and facts, catching fake content, and so on. The exposition will especially elucidate the adversarial approaches in deep learning to detect counterfeit content that could come in any form like text, images, videos, or audio. In doing so, we establish the importance of generating plausible and understandable explanations for model predictions with a special emphasis on algorithm fairness. With the fact that deep learning methods rely on comparatively larger datasets of top-notch quality, this chapter will also highlight the availability of relevant datasets in this space, as well as share pointers to curate one if needed. Even with sufficient data, however, detection problems in this domain are especially challenging since spammers and fake content generators are working tirelessly to evolve their strategies in parallel to the advancement in detection mechanisms. We will further shed some light on some recent and upcoming trends from the aspect of fake news contributors, and critically evaluate how our current state-of-the-art deep learning techniques fare against those. In closing, we will leave readers with some thoughts on future directions for the development of better and smarter fake news detectors. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	keywords = {Fake detection; Information dissemination; Learning systems; Social networking (online); Comparatives studies; Information propagation; Learning models; Media campaigns; News reporting; Power; Social media; Socio-economics; State of the art; Text images; Deep learning},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}